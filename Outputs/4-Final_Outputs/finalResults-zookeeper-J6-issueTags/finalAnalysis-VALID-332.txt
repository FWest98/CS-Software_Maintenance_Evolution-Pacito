Pattern changes caused by commit: a4c675afff3b26171efd78ced4916e2f5fb25eb4

From: Flyweight-1
To:   Flyweight-2


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-332.txt 

commit a4c675afff3b26171efd78ced4916e2f5fb25eb4
Author: Mahadev Konar <mahadev@apache.org>

    ZOOKEEPER-231. Quotas in ZooKeeper. (mahadev)



==================================
 Issue ZOOKEEPER-231 Description 
=======================================

Project: ZooKeeper
-----------------

-----------------
Title: [ZOOKEEPER-231] Quotas in zookeeper
-----------------

-----------------
Summary: Quotas in zookeeper
-----------------

-----------------
Issue type: New Feature
-----------------

-----------------
Current status: Closed
-----------------

-----------------
Created at: Fri, 21 Nov 2008 21:13:13 +0000
-----------------

-----------------
Resolved at: Tue, 3 Feb 2009 05:26:51 +0000
-----------------

-----------------
Assigned to: Mahadev Konar
-----------------

-----------------
Description: 

creating quota's in zookeeper so that a runaway application does not bring down the
zookeeper cluster.
 

-----------------

-----------------
Comments: 

New Comment: 
I will put up a proposal shortly ... 


New Comment: 
here is a proposal for quotas &#8211; The goal:<ul class="alternate"
type="square">	<li>prevent run away processes or applications bringing down the
service.</li>	<li>providing admins to look at usage and being able to monitor
proactively</li></ul>What kind of quoata would we have<ul class="alternate"
type="square">	<li>namespace quotas</li>	<li>bytes quota</li></ul>Proposal:<ul
class="alternate" type="square">	<li>Reserve the node /zookeeper for zookeeper stats and
zookeeper data management.</li>	<li>reserve /zookeeper/quota/ for quota related data
structures</li></ul>The proposal is to have subtree based quotas for the number of bytes
and number of nodes as well.<br/>The monitoring of quotas and stats should be availabe
through the command port <br/>and through zookeeper itself via the /zookeeper node.The
proposal is to have something like
<br/>/zookeeper/quota/path/limits/size<br/>/zookeeper/quota/path/usage/size<br/>/zookeeper/quota/path/limits/count<br/>/zookeeper/quota/path/usage/countlimits
are the stored values that signify the limit for a subtree path<br/>and usage denote the
actual usage of the subtree in terms of bytes or count or number of writes/reads. 


New Comment: 
so we eat sizeof(path)x8 to set quotas?  isn't that excessive?  also seems overly
difficult to administer. 


New Comment: 
Couple of points:<br/>a) We could set the <b>total</b> bytes used by one client. If it is
a runaway process, sooner or later it will exceed the limit anway<br/>b)How would we
handle the identity ? Do we assume a secure environment or a hostile one ? Reason being,
if someone wants to expose ZooKeeper as an internet service, wat kind of safeguards do we
need ? Secure identity mechanisms ? 


New Comment: 
Sorry for the second comment.<br/>I suddenly realized, what Mahadev is proposing is a per
path quota and not a per client quota. SO when a path exceeds a limit, we just prune the
path. A runaway client most probably will again fillup the path and we prune
again.<br/>May be we should have a per client model
/zookeeper/quota/&lt;ipAddress&gt;/usage. ust accumulate the siz of all artifacts the
client stores with ZooKeeper. Of course, when the limit exceeds, we would have to deny
storage for that client and this has the potential for DOS. 


New Comment: 
in response to allen's comments:we expect that the admin's will have some common subtree
for users/apps<br/>something like /apps/app1 &#8211; so in that case it would just add one
node for a new user and in zookeeepr 1 node corresponds to 100 bytes or so.so usage should
not be a problem.also regarding administration, we will expose the setting and getting of
these quotas using jmx and will have command line tools to do that and get stats.
@krishna's comments:it would a huge overhead to track usage/stats per client since the
clients are usually distributed and of the ordeor of thousands.<br/>does that make sense? 


New Comment: 
Another issue with perclient tracking - what if an IP is running multiple clients (within
or across processes). It seems to me that having quotas based on subtrees
(application/service) make much more sense./app/app1 10mb<br/>/app/app2/service1
10mb<br/>/app/app2/service2 10mb<br/>/app/app3 30mb<br/>etc...Regardless of the number of
clients i've limited a particular service/application to a set space. 


New Comment: 
@Mahadev:<br/>I thought there would be much more trees than clients. So if tracking per
client is high overhead, wouldn't that apply to the trees ? What is the normal arit
between clients/trees ? Again we are talking about clients that store something not the
ones that refer to the nodes<br/>@Patrick<br/>Application/Service makes sense, but how
would we reliably know the app name and also deal efficiently with duplicates ? 


New Comment: 
@krishna:<br/>a distributed application say A1 might have thousands of clients of
Zookeeper. So, the idea is that the admins assign /apps/a1 for application A1 (set them up
with proper acls so that only A1 is able to access it). also for reliably knowing the app
name we would have some kind of authorization for a client to identify itself as a part of
some application. initially it could just be something like <br/>instantiating a
zookeeper-client with an application name. (no security). 


New Comment: 
@Krishna: the paths I specified are zk subtree path specs.I should have been more clear:
/app/app1 corresponds to the /app/app1 znode subtree w/in ZK namespace.  To take my
example further you might
have:/app/app1/cluster1/members/...<br/>/app/app1/cluster1/leader<br/>/app/app1/cluster2/members/...<br/>/app/app1/cluster2/leaderwhere
members is storing the hosts &amp; ports of the members of cluster1, for app1, etc... and
leader is storing the leader node for the cluster (this is but one simple example).The ZK
ACLs feature could be used to lock down a particular acl id to particular
subtree(s).<br/><a
href="http://hadoop.apache.org/zookeeper/docs/r3.0.0/zookeeperProgrammers.html#sc_ZooKeeperAccessControl"
class="external-link"
rel="nofollow">http://hadoop.apache.org/zookeeper/docs/r3.0.0/zookeeperProgrammers.html#sc_ZooKeeperAccessControl</a>So
in this case you might have acl ids for app1, app2 and app3, each only able to access it's
particular corresponding subtree of znodes, where each of those trees has some associated
quota.Does that help? 


New Comment: 
Adding a link to <a href="https://issues.apache.org/jira/browse/ZOOKEEPER-119"
title="Reserve &quot;.zookeeper&quot; node for server use." class="issue-link"
data-issue-key="ZOOKEEPER-119">ZOOKEEPER-119</a>Originally we talked about using
/.zookeeper rather than /zookeeper, have we changed our minds on whether that's a good
idea or not? 


New Comment: 
@Patrick,<br/> Yep, that helps. But raises another question ;o). RE:acl id, woud it be a
good idea to get couple more double clicks and granularities ? Eg&gt; app and some sort of
id at the next level. May be app is sufficient. For now, looks like our least count is ip,
but there are more smaller leaf units than that, like app.Cheers<br/>&lt;k/&gt; 


New Comment: 
@krishna<br/>zookeeper has a pluggalbe authorization system. So in case you want to use ip
as the granularities instead of an app, then you can create an authorization system with
id = ipaddress.<br/>scheme=ipschemewhich classifies the ipaddesses into one of the subnet
ids? ... we already have one such auth system using subnet authorization in
<br/>src/java/main/org/apache/zookeeper/server/auth/IPAuthenticationProvider.java 


New Comment: 
here is a preliminary patch for qutoa's. This is not fully complete &#8211; lacking tests,
documentation and a few minor features, which I will be adding shortly. The design is
based on whats discussed above. COmments are welcome. 


New Comment: 
here is a more recent patch (needs testing). it does not include tests and docs &#8211;
will be adding them. 


New Comment: 
updated patch ... shaked out some bugs... still needs tests and documentation... please
review the code.... ill be making some changes .... but not drastic ones... the one thing
to keep in mind is htat the current code forbids setting of quota if a path "does not"
already exist (just an easier implementation choice) ... I will be changing that to
setting of quota only if a path exists. 


New Comment: 
this patch includes a test and documentation. The only thing I have to change is to allow
setting quota only for paths athat exist. I will be adding more tests and more
documentation. I will make it patch available to get early feedback.. 


New Comment: 
fixed a bug that i found while debugging... 


New Comment: 
Here is the latest patch. THis patch has the following &#8211; <ul class="alternate"
type="square">	<li>quota can be set via the commadn line using setQuota -n|-b
path</li>	<li>quota can be deleted via the commandline using delQuota <span
class="error">&#91;-n|-b&#93;</span> path</li>	<li>setting quota for a node that does not
exist will throw an exception</li>	<li>setting quota for a node that has an ancestor or a
descendant that has a quota cannot be set</li>	<li>includes a simeple test case &#8211;
their are lot of corner cases. I am still trying to add more</li>	<li>includes
documentation (please review the documentation to see if you understand how to use
quotas)</li>	<li>their are a lot of corner cases &#8212; feel free to test them and
mention it on the jira &#8211; i will tru and write a test case for that.</li></ul> 


New Comment: 
forogt to mention- <ul class="alternate" type="square">	<li>to list the quota limit and
usage use listquota path</li></ul> 


New Comment: 
This might be a naive question, but what happens if I create a znode with x bytes, and I
try to set a quota for "x' &lt; x"? My guess is that the setQuota operation will fail. If
this is correct, then the semantics is a little awkward because the service doesn't allow
me to set a quota for a given znode that might be using too much space. Along the same
lines, why not enabling to set quotas for nodes that do not exist? Because the create call
enables a client to add data to a new node, it might be desirable to set a quota before
creating the node. I was also wondering about performance. Do you have an idea if this
quota scheme will affect our throughput performance? 


New Comment: 
added a junit test to run with QUorum for quotas. 


New Comment: 
Refactored the QuorumTest to create a quorumBase class like clientbase. Had to make some
changes in the testcases to get it to working after the refactoring. 


New Comment: 
there are a number of issues I found, I have an updated patch in progress 


New Comment: 
addressed a few issues in the patch:1) updated to apply against latest svn with no
rejects<br/>2) fixed handling of parent quota checking - was failing due<br/>to / char
being at end of path - now checked by client and server code<br/>3) fixed forrest docs for
site/index page<br/>4) cleaned up some imports<br/>5) some spelling issues<br/>6) added
eof newlines to some files that were missing<br/>7) @Override on interface method caused
compilation to fail on 1.5 - removed 


New Comment: 
+1. It looks good to me, it compiles without problems, and tests run fine. 


New Comment: 
I just committed this. 


