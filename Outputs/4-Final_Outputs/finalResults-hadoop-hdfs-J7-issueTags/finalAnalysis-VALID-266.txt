Pattern changes caused by commit: 9df4e54aa24748b186837df8574e5d2d4bb351cb

From: Mediator-0
To:   Mediator-1


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-266.txt 

commit 9df4e54aa24748b186837df8574e5d2d4bb351cb
Author: Konstantin Shvachko <shv@apache.org>

    HDFS-512. Block.equals() and compareTo() compare blocks based only on block Ids, ignoring generation stamps. Contributed by Konstantin Shvachko.



==================================
 Issue HDFS-512 Description 
=======================================

Project: Hadoop HDFS
-----------------

-----------------
Title: [HDFS-512] Set block id as the key to Block
-----------------

-----------------
Summary: Set block id as the key to Block
-----------------

-----------------
Issue type: Improvement
-----------------

-----------------
Current status: Closed
-----------------

-----------------
Created at: Wed, 29 Jul 2009 17:05:50 +0000
-----------------

-----------------
Resolved at: Fri, 23 Oct 2009 19:31:22 +0000
-----------------

-----------------
Assigned to: Konstantin Shvachko
-----------------

-----------------
Description: 

Currently the key to Block is block id + generation stamp. I would propose to change it
to be only block id. This is based on the following properties of the dfs cluster:<br/>1.
On each datanode only one replica of block exists. Therefore there is only one generation
of a block.<br/>2. NameNode has only one entry for a block in its blocks map.

With this
change, search for a block/replica's meta information is easier since most of the time we
know a block's id but may not know its generation stamp.
 

-----------------

-----------------
Comments: 

New Comment: 
This patch change Block's key from block id+generation stamp to be block id. It also
removes the class GenerationStamp and the use of generation wild card. 


New Comment: 
Changing the key of the maps from block id and generation stamp to only block id sounds a
good idea.  However, changing the Block.equal(..) method may not be correct. 
Conceptually, block A is not equal to block B, given that they have the same id but
distinct generation stamps. 


New Comment: 
The way I look at this problem is that I'd like to treat a generation stamp as a property
of a block just as the property block length. The only key to identify a block is the
block id. 


New Comment: 
&gt; The way I look at this problem is that I'd like to treat a generation stamp as a
property of a block just as the property block length. The only key to identify a block is
the block id.If this is a new class, you are right that we can view it that way.  However,
Block is an existing base class and it is there for a very long time.  We cannot simply
view it in one way yesterday and view it in another way today.  Also, it belongs to the
org.apache.hadoop.hdfs.protocol package.  This may potentially break some external
applications.Inside hdfs, there are<ul class="alternate"
type="square">	<li>HashMap&lt;Block, BlockScanInfo&gt; blockMap in
DataBlockScanner</li>	<li>Map&lt;Block, BalancerBlock&gt; globalBlockList in
Balancer</li>	<li>List&lt;HashMap&lt;Block, BalancerBlock&gt;&gt; movedBlocks in
Balancer.MovedBlocks</li>	<li>Map&lt;Block, PendingBlockInfo&gt; pendingReplications in
PendingReplicationBlocks</li>	<li>List&lt;TreeSet&lt;Block&gt;&gt; priorityQueues in
UnderReplicatedBlocks</li>	<li>BlockInfo extends Block</li>	<li>BlockMetaDataInfo extends
Block</li>	<li>...</li></ul>Have you considered the implication to them? 


New Comment: 
&gt; Block is an existing base class and it is there for a very long time. We cannot
simply view it in one way yesterday and view it in another way today.<br/>I agree that
Block is a long existing base class. But I disagree that we could not do any change to it.
Adding generation stamp as a part of its key was introduced by the append project. As I
think more on the new append design, I feel that this was a design flaw and has caused
many problems that we could not handle multiple generation stamps. That's why I want to
make the proposed change.As I said in the description of this jira, this change is based
on the following facts: (1) On each datanode only one replica of block exists. Therefore
there is only one generation of a block. (2) NameNode has only one entry for a block in
its blocks map. So in all the maps that you mentioned, there should be only one entry of a
block per block id. In either NN or DN, there is only one entry of blockInfo or
replicaInfo per block. I do not think changing the key of the Block should cause any
problem to all these data structures in dfs. If there are two generations of a block in
those data structures, this is an error. Whether the key contains generation stamp or not,
dfs should handle this error.I agree this may break some external applications. We could
put this change in the release note. 


New Comment: 
Hairong, if my concerns are carefully considered, I won't veto the changes although the
changes are still very dangerous.I suggest to keep WILDCARD_STAMP and use it for sanity
check as shown below.<div class="code panel" style="border-width: 1px;"><div
class="codeContent panelContent"><pre class="code-java"><span
class="code-comment">//Block</span>  <span class="code-keyword">public</span> <span
class="code-object">boolean</span> equals(<span class="code-object">Object</span> o) {   
...    <span class="code-keyword">final</span> Block that = (Block)o;    <span
class="code-keyword">if</span> (<span class="code-keyword">this</span>.generationStamp !=
that.generationStamp &amp;&amp; that.generationStamp != WILDCARD_STAMP) {      <span
class="code-keyword">throw</span> <span class="code-keyword">new</span>
IllegalArgumentException(..);    }    <span class="code-keyword">return</span> ... 
}</pre></div></div> 


New Comment: 
For your reference, generation stamp and the change of Block.equals(..) were introduced by
<a href="https://issues.apache.org/jira/browse/HADOOP-2656" title="Support for upgrading
existing cluster to facilitate appends to HDFS files" class="issue-link"
data-issue-key="HADOOP-2656"><del>HADOOP-2656</del></a>. 


New Comment: 
Most of the maps Nicholas listed above are <tt>HashMap}}s. They are based on
{{Block.hash()</tt> method, which is not modified by the patch, and has never used
generation stamp in calculating block's hash. I found only 4 maps, which use
<tt>TreeSet&lt;Block&gt;</tt> or <tt>TreeMap</tt> with the <tt>Block</tt> as a key. Here
they
are:<ol>	<li>UnderReplicatedBlocks</li>	<li>BlockManager.excessReplicateMap</li>	<li>CorruptReplicasMap</li>	<li>DatanodeDescriptor.invalidateBlocks</li></ol>Neither
of them need to know about generation stamp.<br/>I think it is safe to make the change. We
should commit it to the append branch.Additional comments:<ul class="alternate"
type="square">	<li><tt>getReplicaInfo()</tt> adds generation stamp checking. I don't think
this is necessary.</li>	<li>comment <tt>// ... ignore generation stamp!!!</tt> is
misleading, should be removed.</li>	<li><tt>ReplicaInfo.setGenStamp(), getGenStamp()</tt>
should rather be called <tt>setGenerationStamp(), getGenerationStamp()</tt></li>	<li>Why
does <tt>ReplicaInfo</tt> need genStamp field. Don't we always have it in <tt>Block</tt>?
If we do could you please add a comment clarifying what this field actually is.</li></ul> 


New Comment: 
&gt; Most of the maps Nicholas listed above are HashMap}}s. They are based on
{{Block.hash() method ...HashMap, like any class implementing Map, also uses equals(..). 
See <a href="http://java.sun.com/javase/6/docs/api/java/util/Map.html"
class="external-link" rel="nofollow">Map API</a>. 


New Comment: 
I was looking at compareTo(), which is used in TreeMap. HashMap uses equals() so yes all
maps are affected.<br/>I still think the change makes sense because we don't want to treat
the same block with different generation stamps as separate blocks.<br/>By the way,
equals() should probably be implemented via compareTo() so that they are always in sync. 


New Comment: 
&gt; I was looking at compareTo(), which is used in TreeMap. ...<br/>Even for TreeMap, it
is good to implement equals(..) correctly as described by the <a
href="http://java.sun.com/javase/6/docs/api/java/util/TreeMap.html" class="external-link"
rel="nofollow">TreeMap API</a>,<blockquote>.. The behavior of a sorted map is well-defined
even if its ordering is inconsistent with equals; it just fails to obey the general
contract of the Map interface.</blockquote>&gt; By the way, equals() should probably be
implemented via compareTo() so that they are always in sync.<br/>Agree. 


New Comment: 
&gt; Why does ReplicaInfo need genStamp field. Don't we always have it in Block? If we do
could you please add a comment clarifying what this field actually is.<br/>Now the key is
block id so the returned entry from the map may have a different generation stamp but
there is no efficient way to get the key in the map so I add the generation stamp to the
value field. 


New Comment: 
I faced this problem before : you can't easily get actual block from the block info in DN.
This is probably a good time to add Block to ReplicaInfo. I think it makes sense and we
don't need to add genStamp and genstamp interface there.. also we don't have to keep
genStamp in Block and in ReplicaInfo in-sync. 


New Comment: 
There are some advantages to using the generation stamp as part of the unique identifier
for a Block object. This ensures that all code correctly identifies that blocks with
different generation stamp are different blocks and can have different contents inside
them. It might not be a big deal for NN data structures, especially because the NN first
checks to see if a block belongs to a file before inserting it into the BlocksMap. But for
external tools that use a block interface (e.g. Balancer, fsck, etc), it might be helpful
for them to understand that blocks with different generation stamps are different blocks
(do these utilities use the Block object at all?)@Raghu: &gt; This is probably a good time
to add Block to ReplicaInfo. If we follow Raghu's suggestion, then can we continue using
the genstamp as part of the Block key?There are other cases, (especially during block
report processing) where we would have to do wild-card lookups for a block. But the cost
of these extra lookup calls might be minimal because they will be in the error-code-path
only. 


New Comment: 
&gt; This is probably a good time to add Block to ReplicaInfo. <br/>I already redefined
ReplicaInfo in <a href="https://issues.apache.org/jira/browse/HDFS-509" title="Redesign
DataNode volumeMap to include all types of Replicas" class="issue-link"
data-issue-key="HDFS-509"><del>HDFS-509</del></a> where ReplicaInfo extends Block. This
patch provides only a temporary fix if <a
href="https://issues.apache.org/jira/browse/HDFS-509" title="Redesign DataNode volumeMap
to include all types of Replicas" class="issue-link"
data-issue-key="HDFS-509"><del>HDFS-509</del></a> gets committed later.&gt; If we follow
Raghu's suggestion, can we continue using the genstamp as part of the Block key?<br/>In
both NN and DN, blocksMap and replicasMap do not need gen stamp as part of the Block key.
DN can provision read if it has a replica with a gen stamp equal to or newer than the one
in the request. With the new design, if DN receives a write request with a recovery flag,
it can satisfy the request if it has a replica with a gen stamp equal to or newer than the
one in the write request.The key question is that does HDFS have any maps or sets that
need to contain two instances of Block with the same block id but different gen stamps. If
the answer is no, we can safely remove the gen stamp as part of the Block key. 


New Comment: 
&gt; does HDFS have any maps or sets that need to contain two instances of Block with the
same block id but different gen stampsI agree, that this is not the case. So, let's get
rid of  the genstamp from the the Block key. Can we still use it in the Block.equals()
method? 


New Comment: 
&gt;  let's get rid of the genstamp from the the Block key. Can we still use it in the
Block.equals() method?I agree the block is identified by the blockID only in all maps.
This by the way should simplify life for external tools too.<br/>We cannot have
semantically different implementations of <tt>compareTo()</tt> and <tt>equals()</tt>
methods. This is what we discussed earlier with Nicholas. <tt>equals()</tt> should be
implemented as <tt>compareTo() == 0</tt>.  <tt>compareTo()</tt> is used by TreeMaps, while
HashMaps are based on <tt>equals()</tt>, so they have to be in sync if we want the same
indexing by different types of maps. 


New Comment: 
Yes, sounds good to me. 


New Comment: 
&gt; We cannot have semantically different implementations of compareTo() and equals()
methods. ...<br/>We indeed could have two implementations of compareTo() since we may pass
a Comparator object.  See <a
href="http://java.sun.com/javase/6/docs/api/java/util/TreeMap.html#TreeMap%28java.util.Comparator%29
API" class="external-link" rel="nofollow">this TreeMap constructor</a>. 


New Comment: 
You are not proposing doing it or are you? 


New Comment: 
I am proposing we should consider this option if it is not yet considered. 


New Comment: 
I am confused. What do you want to use two different comparators for? 


New Comment: 
&gt; .. What do you want to use two different comparators for? <br/>We may keep current
Block.compareTo(..) and Block.equals(..) implementations (i.e. the use id and gs) and then
define a new Comparator&lt;Block&gt; for comparing only id. 


New Comment: 
I understand we can implement multiple comparators. But my question is what are the use
cases for them? You propose two: where do you plan to use each of them? 


New Comment: 
From my understanding, we want to change some map keys from id + gs to id.  Then, we have
a few options<br/>(1) change Block.compareTo(..) and Block.equals(..) to compare on
id.<br/>(2) change class of the map keys from Block to something else, say BlockId, which
only uses id (but not gs) to implement equals (and compareTo).<br/>(3) use TreeMap with
Block as the key but define a new Comparator which compare Block(s) with id only.Current
patch implements option (1).  We may consider options (2) and (3). 


New Comment: 
I forgot to say that my preference would be (2) &gt; (3) &gt; (1) because<ul
class="alternate" type="square">	<li>(1) is too dangerous to get everything correct and is
an incompatible change; and</li>	<li>(3) seems requiring more code changes than
(2).</li></ul> 


New Comment: 
We have a concern that whether compareTo(..) has to be consistent with equal(..).  The
answer is "strongly recommended but not required".  See <a
href="http://java.sun.com/javase/6/docs/api/java/lang/Comparable.html"
class="external-link" rel="nofollow">the Comparable API</a>.<blockquote>It is strongly
recommended (though not required) that natural orderings be consistent with equals.
...</blockquote> 


New Comment: 
&gt; (1) is too dangerous to get everything correctI want to see at least one example
where current the implementation (id+gs) of the block key is critical.&gt; and is an
incompatible change;I agree it is. BTW, nobody complained about changing it from id to
(id+gs).&gt; (2) change class of the map keys from Block to something else, say
BlockIdThis is going to cost us. Currently BlocksMap entry key and value are the same
object. So the key is represented by a reference only. In your proposal (2) replacing the
key with BlockID it is going to be a new object, which will tale more space than a
reference.<br/>Unless you implement <tt>BlockInfo.equals()</tt> differently. Right now it
simply refers to the super class method <tt>Block.equals()</tt>.<br/><tt>BlockInfo</tt> is
not a public api and we can change it, but I still don't know why would we want to
increase the complexity of the code, except the hypothetical suggestion it may cause
problems. 


New Comment: 
&gt; I want to see at least one example where current the implementation (id+gs) of the
block key is critical.<br/>I did not say that I got a good example for using id+gs.&gt;
(1) is too dangerous to get everything correct<br/>Typo: it should be "(1) is too
dangerous: it is very difficult to get everything correct"<br/>I mean (1) involves too
much.  I even have a hard time to list out all the affected components in <a
href="https://issues.apache.org/jira/browse/HDFS-512?focusedCommentId=12737395&amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12737395"
class="external-link" rel="nofollow">my previous comment</a>.BTW, I am not against (1) and
I am not the assignee of this issue.  Please go ahead if you have fully considered other
alternatives.  I think the assignee has the freedom to choose a solution. 


New Comment: 
Here is another variant of the patch. <ul class="alternate" type="square">	<li>I changed
<tt>Block.compareTo()</tt> to compare only the block Ids, and <tt>Block.equals()</tt> now
returns <tt>compareTo() == 0</tt>.</li>	<li>I removed <tt>FSBanesystem.findBlock(id)</tt>,
since it is not required any more, abd pieces of the code that depended on non-equal
generation stamps.</li>	<li>Found that we have two identical methods
<tt>getGenerationStampFromFile()</tt> in FSDatataset, remove one, which does not have
references.</li>	<li>Unlike previous patch I think it is better to keep
<tt>GenerationStamp</tt> class around. It keeps generation stamp related constants and
implements <tt>nextStamp(), setStamp()</tt>. I don't see why it need to be
Writable.</li></ul> 


New Comment: 
I ran test-core and test-patch myself. It works. Need to run map-reduce tests to make sure
nothing is affected by this change. 


New Comment: 
-1 overall.  Here are the results of testing the latest attachment <br/>  <a
href="http://issues.apache.org/jira/secure/attachment/12422175/blockIdAsKey.patch"
class="external-link"
rel="nofollow">http://issues.apache.org/jira/secure/attachment/12422175/blockIdAsKey.patch</a><br/>
 against trunk revision 825689.    +1 @author.  The patch does not contain any @author
tags.    +1 tests included.  The patch appears to include 9 new or modified tests.    +1
javadoc.  The javadoc tool did not generate any warning messages.    +1 javac.  The
applied patch does not increase the total number of javac compiler warnings.    +1
findbugs.  The patch does not introduce any new Findbugs warnings.    +1 release audit. 
The applied patch does not increase the total number of release audit warnings.    -1 core
tests.  The patch failed core unit tests.    +1 contrib tests.  The patch passed contrib
unit tests.Test results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/27/testReport/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/27/testReport/</a><br/>Findbugs
warnings: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/27/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/27/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html</a><br/>Checkstyle
results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/27/artifact/trunk/build/test/checkstyle-errors.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/27/artifact/trunk/build/test/checkstyle-errors.html</a><br/>Console
output: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/27/console"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/27/console</a>This
message is automatically generated. 


New Comment: 
FSNamesystem.java has code that removes a blockinfo entry from the blocksMap, changes its
generation stamp, and adds it back, for example, in updatePipeline and
commitBlockSynchronization. Now that the generation stamp is not the part of the key,
those code are not necessary. 


New Comment: 
This is merging the current trunk.<br/>I also fixed updatePipeline() as Hairong
suggested.<br/>I did not fix commitBlockSynchronization(). I think it should be a
refactoring task for another jira. 


New Comment: 
I ran tests for HDFS and MapReduce, inculding contrib tests for both projects. Everything
worked fine with the new keys. Also talked to Devaraj, who could not find a reason why MR
would care about blocks' generation stamps. 


New Comment: 
+1 overall.  Here are the results of testing the latest attachment <br/>  <a
href="http://issues.apache.org/jira/secure/attachment/12422973/blockIdAsKey.patch"
class="external-link"
rel="nofollow">http://issues.apache.org/jira/secure/attachment/12422973/blockIdAsKey.patch</a><br/>
 against trunk revision 828926.    +1 @author.  The patch does not contain any @author
tags.    +1 tests included.  The patch appears to include 9 new or modified tests.    +1
javadoc.  The javadoc tool did not generate any warning messages.    +1 javac.  The
applied patch does not increase the total number of javac compiler warnings.    +1
findbugs.  The patch does not introduce any new Findbugs warnings.    +1 release audit. 
The applied patch does not increase the total number of release audit warnings.    +1 core
tests.  The patch passed core unit tests.    +1 contrib tests.  The patch passed contrib
unit tests.Test results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/54/testReport/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/54/testReport/</a><br/>Findbugs
warnings: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/54/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/54/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html</a><br/>Checkstyle
results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/54/artifact/trunk/build/test/checkstyle-errors.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/54/artifact/trunk/build/test/checkstyle-errors.html</a><br/>Console
output: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/54/console"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/54/console</a>This
message is automatically generated. 


New Comment: 
+1. The patch looks good to me. 


New Comment: 
I just committed this. 


New Comment: 
Integrated in Hadoop-Hdfs-trunk-Commit #81 (See <a
href="http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk-Commit/81/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk-Commit/81/</a>)<br/>
   . Block.equals() and compareTo() compare blocks based only on block Ids, ignoring
generation stamps. Contributed by Konstantin Shvachko. 


New Comment: 
Integrated in Hdfs-Patch-h2.grid.sp2.yahoo.net #59 (See <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/59/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/59/</a>) 


New Comment: 
Integrated in Hadoop-Hdfs-trunk #120 (See <a
href="http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk/120/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk/120/</a>) 


