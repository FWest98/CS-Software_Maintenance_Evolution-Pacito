Pattern changes caused by commit: 61f78ca936768aea56764dee2fdb21bd59ecdf0b

From: Mediator-1
To:   Mediator-0


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-470.txt 

commit 61f78ca936768aea56764dee2fdb21bd59ecdf0b
Author: Dhruba Borthakur <dhruba@apache.org>

    HDFS-1109. HFTP supports filenames that contains the character "+".
    (Dmytro Molkov via dhruba)



==================================
 Issue HDFS-1109 Description 
=======================================

Project: Hadoop HDFS
-----------------

-----------------
Title: [HDFS-1109] HFTP and URL Encoding
-----------------

-----------------
Summary: HFTP and URL Encoding
-----------------

-----------------
Issue type: Bug
-----------------

-----------------
Current status: Closed
-----------------

-----------------
Created at: Fri, 23 Apr 2010 23:40:15 +0000
-----------------

-----------------
Resolved at: Mon, 10 May 2010 19:08:07 +0000
-----------------

-----------------
Assigned to: Dmytro Molkov
-----------------

-----------------
Description: 

We just saw this error happen in our cluster. If there is a file that has a "+" sign in
the name it is not readable through HFTP protocol.<br/>The problem is when we are reading
a file with HFTP we are passing a name of the file as a parameter in request and + gets
undecoded into space on the server side. So the datanode receiving the streamFile request
tries to access a file with space instead of + in the name and doesn't find that
file.

The proposed solution is to pass the filename as a part of URL as with all the
other HFTP commands, since this is the only place where it is not being treated this way.
Are there any objections to this?
 

-----------------

-----------------
Comments: 

New Comment: 
This will also be server side only change. There are two servlets that get affected by it
the FileDataServlet and StreamFile, since you cannot run cluster with namenode and
datanode not synced on build version there is no breaking compatibility. 


New Comment: 
just curious, why not url encode the +?<a
href="http://blooberry.com/indexdot/html/topics/urlencoding.htm" class="external-link"
rel="nofollow">http://blooberry.com/indexdot/html/topics/urlencoding.htm</a>%2B would
result in '+'(w/o examples, maybe I don't see the precise problem, sorry) 


New Comment: 
Well, it will essentially serve the same purpose. We could either url encode and decode
that parameter being passed to streamFile servlet. Or change it to be url path instead of
url parameter. Since all other HFTP operations pass the path of the file as the url path
changing the streaming servlet to follow the same logic. 


New Comment: 
Ah, I see.  I actually agree making the file part of the path is a cleaner approach (put
the resource there as the URI spec suggests).  I think my question was more about if there
was a way to do it w/o changing the HFTP api--I think the url encoding approach would
maintain compatibility.  A new client could url encode and by default, I believe jetty
will url decode the string and hence not require a server change.that said, i don't
object.  just throwing the thought out there 


New Comment: 
This url request is being generated in the namenode as a redirect for client. Client first
contacts the namenode with a path to read, and this path is not url decoded when namenode
performs its operations (I was getting exceptions with file not existing when encoding +
by hand), then the client is forwarded to a datanode with a new url where the path is
passed as a parameter and it is not decoded either, so it is either way namenode +
datanode servlets modification. 


New Comment: 
Attaching a patch. It also affects HDFSProxy code, would like someone who knows about that
part to review this one.<br/>It also introduces TestHftpFileSystem unittest to test the
specific problem this patch is solving, but since there was no test for hftp before it
should serve as an initial test for Hftp in general.<br/>The patch also fixes the problem
introduced by <a href="https://issues.apache.org/jira/browse/HDFS-991" title="Allow
browsing the filesystem over http using delegation tokens" class="issue-link"
data-issue-key="HDFS-991"><del>HDFS-991</del></a> which threw NPE when trying to read a
file through HFTP (stream file servlet was getting name.conf from the datanode context) 


New Comment: 
Submitting for tests. 


New Comment: 
-1 overall.  Here are the results of testing the latest attachment <br/>  <a
href="http://issues.apache.org/jira/secure/attachment/12442918/HDFS-1109.patch"
class="external-link"
rel="nofollow">http://issues.apache.org/jira/secure/attachment/12442918/HDFS-1109.patch</a><br/>
 against trunk revision 937914.    +1 @author.  The patch does not contain any @author
tags.    +1 tests included.  The patch appears to include 12 new or modified tests.    +1
javadoc.  The javadoc tool did not generate any warning messages.    +1 javac.  The
applied patch does not increase the total number of javac compiler warnings.    +1
findbugs.  The patch does not introduce any new Findbugs warnings.    -1 release audit. 
The applied patch generated 113 release audit warnings (more than the trunk's current 112
warnings).    -1 core tests.  The patch failed core unit tests.    -1 contrib tests.  The
patch failed contrib unit tests.Test results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/327/testReport/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/327/testReport/</a><br/>Release
audit warnings: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/327/artifact/trunk/patchprocess/releaseAuditDiffWarnings.txt"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/327/artifact/trunk/patchprocess/releaseAuditDiffWarnings.txt</a><br/>Findbugs
warnings: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/327/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/327/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html</a><br/>Checkstyle
results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/327/artifact/trunk/build/test/checkstyle-errors.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/327/artifact/trunk/build/test/checkstyle-errors.html</a><br/>Console
output: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/327/console"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/327/console</a>This
message is automatically generated. 


New Comment: 
Reattaching the patch with license header in the new test. 


New Comment: 
-1 overall.  Here are the results of testing the latest attachment <br/>  <a
href="http://issues.apache.org/jira/secure/attachment/12442924/HDFS-1109.2.patch"
class="external-link"
rel="nofollow">http://issues.apache.org/jira/secure/attachment/12442924/HDFS-1109.2.patch</a><br/>
 against trunk revision 937914.    +1 @author.  The patch does not contain any @author
tags.    +1 tests included.  The patch appears to include 8 new or modified tests.    +1
javadoc.  The javadoc tool did not generate any warning messages.    +1 javac.  The
applied patch does not increase the total number of javac compiler warnings.    +1
findbugs.  The patch does not introduce any new Findbugs warnings.    +1 release audit. 
The applied patch does not increase the total number of release audit warnings.    +1 core
tests.  The patch passed core unit tests.    -1 contrib tests.  The patch failed contrib
unit tests.Test results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/328/testReport/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/328/testReport/</a><br/>Findbugs
warnings: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/328/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/328/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html</a><br/>Checkstyle
results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/328/artifact/trunk/build/test/checkstyle-errors.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/328/artifact/trunk/build/test/checkstyle-errors.html</a><br/>Console
output: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/328/console"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/328/console</a>This
message is automatically generated. 


New Comment: 
I cannot see the exact failure of hdfsproxy test, but it succeeds on my local
machine.<br/>Can someone please review the patch? 


New Comment: 
I just checked <a href="https://issues.apache.org/jira/browse/HDFS-330" title="Datanode
Web UIs should provide robots.txt" class="issue-link"
data-issue-key="HDFS-330"><del>HDFS-330</del></a> and <a
href="https://issues.apache.org/jira/browse/HDFS-964" title="hdfs-default.xml
shouldn&#39;t use hadoop.tmp.dir for dfs.data.dir (0.20 and lower) / dfs.datanode.dir
(0.21 and up)" class="issue-link" data-issue-key="HDFS-964"><del>HDFS-964</del></a> also
fail the same hdfsproxy test. I cannot figure out why though. This means that 1109 patch
is not affecting the testcase. 


New Comment: 
+1 I reviewed the patch and lgtm 


New Comment: 
Code looks good, I wil commit this by the end of this week unless anybody else has any
review comments. 


New Comment: 
I just resolved this. Thanks Dmytro. 


New Comment: 
<a href="https://issues.apache.org/jira/browse/HDFS-1109" title="HFTP and URL Encoding"
class="issue-link" data-issue-key="HDFS-1109"><del>HDFS-1109</del></a>.2_y0.20.1xx.patch:
for y0.20.1xx 


New Comment: 
Marking this as incompatible change since it changed the internal url query. 


New Comment: 
This change is only incompatible if:<br/>1) Namenode and datanode are of different
versions<br/>2) you are going directly to datanodeOtherwise since this is a server only
change client and server can be<br/>of different (pre fix/post fix) versionsOn Jul 13,
2010, at 5:00 PM, "Tsz Wo (Nicholas), SZE (JIRA)" 


New Comment: 
This change is similar to changing DatanodeProtocol.  We definitely mark it as an
incompatible change if DatanodeProtocol is changed. 


New Comment: 
<a href="https://issues.apache.org/jira/browse/HDFS-1109" title="HFTP and URL Encoding"
class="issue-link"
data-issue-key="HDFS-1109"><del>HDFS-1109</del></a>.2_y0.20.1xx_incremental.patch: for
y0.20.1xx. This is an incremental patch over Nicholas'. It fixes an issue in hdfsproxy
where the filepath in streamFile is not picked up. 


New Comment: 
Hi Rohini, the bug you discovered is not y0.20.1xx specific.  Trunk also has this bug.  So
it is better create a new JIRA in order to fix it since this was already resolved in May. 


New Comment: 
Thanks. Created issue <a href="https://issues.apache.org/jira/browse/HDFS-1317"
class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/HDFS-1317</a>
for the fix in HDFSProxy. 


New Comment: 
Goto namenode web UI -&gt; Browse the filesystem -&gt; click on a file link.The URL sends
the file name as the URL param. However the change made in this patch (see below), looks
for filename in URL path.<div class="preformatted panel" style="border-width: 1px;"><div
class="preformattedContent panelContent"><pre>Index:
src/java/org/apache/hadoop/hdfs/server/datanode/DatanodeJspHelper.java===================================================================---
src/java/org/apache/hadoop/hdfs/server/datanode/DatanodeJspHelper.java	(revision
938218)+++ src/java/org/apache/hadoop/hdfs/server/datanode/DatanodeJspHelper.java	(working
copy)@@ -236,7 +236,9 @@     else       startOffset = Long.parseLong(startOffsetStr); -   
final String filename=JspHelper.validatePath(req.getParameter("filename"));+    final
String filename=JspHelper.validatePath(+                          req.getPathInfo() ==
null ? +                          "/" : req.getPathInfo());</pre></div></div>Why are we
using URL path instead of "filename" param? 


New Comment: 
Linking in <a href="https://issues.apache.org/jira/browse/MAPREDUCE-2052" title="Fix URL
encoding of job history logfiles" class="issue-link"
data-issue-key="MAPREDUCE-2052">MAPREDUCE-2052</a> and <a
href="https://issues.apache.org/jira/browse/MAPREDUCE-1378" title="Args in job details
links on jobhistory.jsp are not URL encoded" class="issue-link"
data-issue-key="MAPREDUCE-1378"><del>MAPREDUCE-1378</del></a> which are relevant. 


New Comment: 
Suresh, the reason for this patch was the way url encoding,decoding works.<br/>We had
files that had a whitespace in the name, when the request got to the datanode the filename
property had a '+' instead of the whitespace (it was url encoded but not decoded). As a
result the datanode couldn't read that file and the HFTP call failed.<br/>Everywhere else
we are using the URL path to pass the hdfs path around except for this case. Changing this
one place deals with the url encoding and the path of the file is passed around properly
in the HFTP protocol. Hope that answers your question. 


New Comment: 
I understood that. The problem is, filename is being passed in "filename" URL parameter
(see my comment on how to duplicate the problem). However the code is using
<tt>req.getPathInfo()</tt> which is null. Hence browsing the file content does not work
any more! 


New Comment: 
Oh, this part is a bug, I never realized that in the web ui it was going after that url
directly instead of using the HFTP kind of call to the namenode to get
redirected.<br/>Should I open a JIRA to fix it? or do you want to reopen this one? 


New Comment: 
We can do it in a separate jira, marking the new one as related to this. 


New Comment: 
Dmytro,<br/>  Is there a separate jira created to fix this issue? This is a blocker for
22. 


New Comment: 
Anyone out there with a version of this patch for 0.20.2? 


New Comment: 
Does <a href="https://issues.apache.org/jira/browse/HDFS-1317" title="HDFSProxy needs
additional changes to work after changes to streamFile servlet in HDFS-1109"
class="issue-link" data-issue-key="HDFS-1317"><del>HDFS-1317</del></a> fix all the
remaining issues, it looks like DfsServlet is still generating redirects  using the
filename parameter. 


New Comment: 
Filed <a href="https://issues.apache.org/jira/browse/HDFS-2236" title="DfsServlet and
FileChecksumServlets still use the filename parameter " class="issue-link"
data-issue-key="HDFS-2236">HDFS-2236</a> for the remaining places that use the filename
parameter. 


New Comment: 
<a href="https://issues.apache.org/jira/browse/HDFS-1575" title="viewing block from web UI
broken" class="issue-link" data-issue-key="HDFS-1575"><del>HDFS-1575</del></a> fixed the
issue viewing blocks from the Web UI. 


