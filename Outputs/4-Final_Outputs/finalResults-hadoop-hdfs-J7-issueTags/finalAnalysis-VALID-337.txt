Pattern changes caused by commit: c344d269c457117eae9de38a6e91b60310f9a655

From: Mediator-1
To:   Mediator-0


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-337.txt 

commit c344d269c457117eae9de38a6e91b60310f9a655
Author: Hairong Kuang <hairong@apache.org>

    HDFS-724. Pipeline hangs when one of the block receiver is not responsive. Contributed by Hairong Kuang.



==================================
 Issue HDFS-724 Description 
=======================================

Project: Hadoop HDFS
-----------------

-----------------
Title: [HDFS-724] Pipeline close hangs if one of the datanode is not responsive.
-----------------

-----------------
Summary: Pipeline close hangs if one of the datanode is not responsive.
-----------------

-----------------
Issue type: Bug
-----------------

-----------------
Current status: Closed
-----------------

-----------------
Created at: Wed, 21 Oct 2009 23:58:38 +0000
-----------------

-----------------
Resolved at: Mon, 21 Dec 2009 23:50:05 +0000
-----------------

-----------------
Assigned to: Hairong Kuang
-----------------

-----------------
Description: 

In the new pipeline design, pipeline close is implemented by sending an additional empty
packet.  If one of the datanode does not response to this empty packet, the pipeline
hangs.  It seems that there is no timeout.
 

-----------------

-----------------
Comments: 

New Comment: 
h724_20091021.patch (not a patch to the bug): fault injection tests to simulate pipeline
close with non-responsive datanode. 


New Comment: 
If a datanode really becomes non-responsive, the dfs client is able to detect the
problem.The issue here is that the test simulates a non-responsive block receiver. While
the block receiver is blocked, the packet responder is still alive and sends heartbeats
back periodically. So the client still thinks the pipeline is working good.The
solution:<br/>1. packet responder does not send heartbeats. instead, turn on the tcp/ip
level heartbeats by setting the socket "keepalive" to be true.<br/>2. dfs client does not
receive acks until there is one outstanding packet. 


New Comment: 
3. another option would be to make the dfsclient send a heartbeat-packet via the pipeline.
Each BlockReceiver in the datanode(s)  recognizes it as a heartbeat packet, and forward it
to the next one in the pipeline. The last datanode , on receipt of this heartbeat-packet
triggers it's PacketResponder to the send back the heartbeat to the previous datanode in
the pipeline. The heartbeat message finally arrives back on the client. This way, we can
test that the entire pipeline (both forward and backward channels) are alive and active. 


New Comment: 
Dhruba, this is a good idea. Dfsclient sends out a heartbeat after the pipeline becomes
idle for half of read timeout. A heartbeat is a special packet with seq# of -1. 


New Comment: 
&gt; Dfsclient sends out a heartbeat after the pipeline becomes idle for half of read
timeout. A heartbeat is a special packet with seq# of -1.+1. 


New Comment: 
I am quite torn at whether a heartbeat should be <br/>1. a regular empty packet and be
handled exactly the same as a regular data packet; or<br/>2. a special empty packet with a
seq# of -1 and be treated differently from a regular packet. For example, it does not get
added to the packet queue at both client or datanode side.Solution 1 is much simpler than
solution 2. But is there any side effect? 


New Comment: 
Agree that solution 1 will be simpler than solution 2. Another thing that might play a
part here is that, over time, we might want to add metadata to the heartbeat packet. (For
example, maybe the timestamp everytime a datanode forwards it; this will enable the client
to eliminate slow datanodes from the pipeline if needed.) 


New Comment: 
The timestamp meta information could be added to regular data packets as well. My plan is
not to send heartbeats periodically. Instead a heartbeat is sent only if the connection is
idle for too long time. 


New Comment: 
&gt; a heartbeat is sent only if the connection is idle for too longsounds good. 


New Comment: 
OK, here comes a patch that does the following:<br/>1. when a pipeline is idle for half of
the read timeout, dfsclient sends a heartbeat packet that has a sequence number of -1 and
a data length of 0;<br/>2. At the client side, a heartbeat packet does not get put the
data queue and hence not in the ack queue;<br/>3. At the datanode side, the block receiver
treats a heartbeat packet mostly like a regular data packet; A heatbeat packet is put in
the ack queue and its ack is also the same as that of a regular data packet;<br/>4. The
ack to a heartbeat packet may also indicate failures in the pipeline and therefore
triggers pipeline recovery. 


New Comment: 
This patch ends up implementing the heartbeat packet as a special packet. This is to avoid
the complexity of both the data stream thread and the application thread creating packets
simultaneously. Otherwise, the dfs client has to handle the issues like synchronization
and out of sequence packets etc. 


New Comment: 
I am still looking at the patch, two comments:1. Is it possible to get rid of
lastDataNodeRun() completely? This method existed because the last datanode in the
pipeline needed to send heartbeats. Now, thatis not needed anymore.2. In DFSClient.java,
one change is:<blockquote>                long timeout = (stage ==
BlockConstructionStage.DATA_STREAMING)?<br/>                  socketTimeout/2 -
(now-lastPacket) : 1000;</blockquote>timeout could sometime be negative? 


New Comment: 
Thanks Dhruba for your review comments. I guess you are still having jet lag. This patch
<br/>1. merges with the trunk (not an easy job <img class="emoticon"
src="https://issues.apache.org/jira/images/icons/emoticons/smile.png" height="16"
width="16" align="absmiddle" alt="" border="0"/>, <br/>2. incorporates Dhruba's comments (
feels scary to remove a large chunk of code), and<br/>3. adds Nicholas' close related
fault injection test which is attached to this jira. 


New Comment: 
-1 overall.  Here are the results of testing the latest attachment <br/>  <a
href="http://issues.apache.org/jira/secure/attachment/12427545/pipelineHeartbeat1.patch"
class="external-link"
rel="nofollow">http://issues.apache.org/jira/secure/attachment/12427545/pipelineHeartbeat1.patch</a><br/>
 against trunk revision 889035.    +1 @author.  The patch does not contain any @author
tags.    +1 tests included.  The patch appears to include 12 new or modified tests.    +1
javadoc.  The javadoc tool did not generate any warning messages.    +1 javac.  The
applied patch does not increase the total number of javac compiler warnings.    +1
findbugs.  The patch does not introduce any new Findbugs warnings.    +1 release audit. 
The applied patch does not increase the total number of release audit warnings.    -1 core
tests.  The patch failed core unit tests.    +1 contrib tests.  The patch passed contrib
unit tests.Test results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/140/testReport/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/140/testReport/</a><br/>Findbugs
warnings: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/140/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/140/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html</a><br/>Checkstyle
results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/140/artifact/trunk/build/test/checkstyle-errors.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/140/artifact/trunk/build/test/checkstyle-errors.html</a><br/>Console
output: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/140/console"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/140/console</a>This
message is automatically generated. 


New Comment: 
This patch additionally handles acks with seqno -2 and some corner cases of the last DN in
pipeline. 


New Comment: 
+1 overall.  Here are the results of testing the latest attachment <br/>  <a
href="http://issues.apache.org/jira/secure/attachment/12427568/pipelineHeartbeat2.patch"
class="external-link"
rel="nofollow">http://issues.apache.org/jira/secure/attachment/12427568/pipelineHeartbeat2.patch</a><br/>
 against trunk revision 889090.    +1 @author.  The patch does not contain any @author
tags.    +1 tests included.  The patch appears to include 12 new or modified tests.    +1
javadoc.  The javadoc tool did not generate any warning messages.    +1 javac.  The
applied patch does not increase the total number of javac compiler warnings.    +1
findbugs.  The patch does not introduce any new Findbugs warnings.    +1 release audit. 
The applied patch does not increase the total number of release audit warnings.    +1 core
tests.  The patch passed core unit tests.    +1 contrib tests.  The patch passed contrib
unit tests.Test results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/83/testReport/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/83/testReport/</a><br/>Findbugs
warnings: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/83/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/83/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html</a><br/>Checkstyle
results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/83/artifact/trunk/build/test/checkstyle-errors.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/83/artifact/trunk/build/test/checkstyle-errors.html</a><br/>Console
output: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/83/console"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/83/console</a>This
message is automatically generated. 


New Comment: 
This is s tough one to review. phew! 


New Comment: 
Let me provide more information about this patch:<br/>1. heart beat is an empty packet
with a sequence number of -1;<br/>2. At the client side, heart beat packets are not queued
in any of the queues because there is no need to resend a heartbeat if there is an error
sending heartbeats.<br/>2. At the datanode side, heartbeats are queued in the ack queue. A
datanode treats a heartbeat the same as a regular data packet. The ack of a heartbeat
packet is the same as a regular data packet as well. To distinguish a heartbeat from an
end-of-block packet, receivePacket returns -1 when receiving an end-of-block
packet.Dhruba, please feel free to reach me if you need more explanation. I need this
patch to be committed before I committing <a
href="https://issues.apache.org/jira/browse/HDFS-101" title="DFS write pipeline :
DFSClient sometimes does not detect second datanode failure " class="issue-link"
data-issue-key="HDFS-101"><del>HDFS-101</del></a>. 


New Comment: 
+1. I was able to look at the entire code and the unit test as well. Thanks for the
explanation. 


New Comment: 
Integrated in Hadoop-Hdfs-trunk-Commit #148 (See <a
href="http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk-Commit/148/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk-Commit/148/</a>) 


New Comment: 
Integrated in Hadoop-Hdfs-trunk #172 (See <a
href="http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk/172/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk/172/</a>) 


New Comment: 
Integrated in Hdfs-Patch-h5.grid.sp2.yahoo.net #148 (See <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/148/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/148/</a>) 


New Comment: 
I've committed this. 


New Comment: 
Integrated in Hdfs-Patch-h2.grid.sp2.yahoo.net #94 (See <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/94/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/94/</a>) 


New Comment: 
I plan to pull in this fix to append20 branch in order to fix <a
href="https://issues.apache.org/jira/browse/HBASE-2861" title="regionserver&#39;s
logsyncer thread hangs on DFSClient$DFSOutputStream.waitForAckedSeqno" class="issue-link"
data-issue-key="HBASE-2861"><del>HBASE-2861</del></a>. 


New Comment: 
+1 for the append-0.20 patch, please check it into the 0.20-append branch. 


New Comment: 
<a href="https://issues.apache.org/jira/browse/HDFS-724" title="Pipeline close hangs if
one of the datanode is not responsive." class="issue-link"
data-issue-key="HDFS-724"><del>HDFS-724</del></a> append0.20 patch does not deserialize
the ack to a heartbeat correctly. Here is the patch that fixes it. 


New Comment: 
I tried it by running a few of the hbase tests that were failing before hbAckReply.patch. 
They pass now (with hdfs-895 in place on 0.20-append).  Let me run the full suite.  I'll
report back.One issue that came up over in hbase-3234 was the fact that hdfs-724 does
this:<div class="code panel" style="border-width: 1px;"><div class="codeContent
panelContent"><pre class="code-java">-  <span class="code-keyword">public</span> <span
class="code-keyword">static</span> <span class="code-keyword">final</span> <span
class="code-object">int</span> DATA_TRANSFER_VERSION = 14;+  <span
class="code-keyword">public</span> <span class="code-keyword">static</span> <span
class="code-keyword">final</span> <span class="code-object">int</span>
DATA_TRANSFER_VERSION = 15;</pre></div></div>Could we not do the above on commit to
0.20-append?  No biggie. Just asking.  Would be nice not making comm incompatible.  Good
stuff Hairong. 


New Comment: 
+1 on the hbAckReply patch.  I ran the hbase tests and all that used fail now passes (with
hdfs-895 in place). 


New Comment: 
Thanks Stack for testing this. I just committed hbAckReply patch to append 0.20 branch.For
the incompatible problem, as I commented on the hbase jira, <a
href="https://issues.apache.org/jira/browse/HDFS-724" title="Pipeline close hangs if one
of the datanode is not responsive." class="issue-link"
data-issue-key="HDFS-724"><del>HDFS-724</del></a> unfortunately changed the syntax and
semantics of heartbeat packets. 


New Comment: 
Patch for 20-security uploaded. 


New Comment: 
This patch does not compile for me. 


New Comment: 
My bad, I had not applied <a href="https://issues.apache.org/jira/browse/HDFS-1057"
title="Concurrent readers hit ChecksumExceptions if following a writer to very end of
file" class="issue-link" data-issue-key="HDFS-1057"><del>HDFS-1057</del></a> patch which
is required for this patch. +1 for the patch. 


