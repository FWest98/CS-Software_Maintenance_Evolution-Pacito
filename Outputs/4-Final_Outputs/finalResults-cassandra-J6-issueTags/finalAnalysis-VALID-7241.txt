Pattern changes caused by commit: 652ae9a6456dd8cdd38e3eebdfbbfad51b2ad197

From: Decorator-1
To:   Decorator-2

From: Flyweight-1
To:   Flyweight-2

From: Mediator-1
To:   Mediator-3

From: Strategy-1
To:   Strategy-0


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-7241.txt 

commit 652ae9a6456dd8cdd38e3eebdfbbfad51b2ad197
Author: Pavel Yaskevich <xedin@apache.org>

    improve DynamicEndpointSnitch by using reservoir sampling
    patch by Pavel Yaskevich; reviewed by Brandon Williams for CASSANDRA-4038



==================================
 Issue CASSANDRA-4038 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-4038] Investigate improving the dynamic snitch with reservoir sampling
-----------------

-----------------
Summary: Investigate improving the dynamic snitch with reservoir sampling
-----------------

-----------------
Issue type: Improvement
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Mon, 12 Mar 2012 22:39:57 +0000
-----------------

-----------------
Resolved at: Mon, 30 Jul 2012 17:15:34 +0000
-----------------

-----------------
Assigned to: Pavel Yaskevich
-----------------

-----------------
Description: 

Dsnitch's UPDATES_PER_INTERVAL and WINDOW_SIZE are chosen somewhat arbitrarily.  A better
fit may be something similar to Metric's ExponentiallyDecayingSample, where more recent
information is weighted heavier than past information, and reservoir sampling would also
be an efficient way of keeping a statistically significant sample rather than refusing
updates after UPDATES_PER_INTERVAL and only keeping WINDOW_SIZE amount.
 

-----------------

-----------------
Comments: 

New Comment: 
Pavel, take a look at this and see if it's worth pursuing. 


New Comment: 
I think it's worth pursuing as that would remove the work we are doing now by restricting
sampling to window size and number of updates in the interval, calculating age of each
response arrival, as well as improve sampling by moving to exponential decay function.
There is already implementation available by Apache 2.0 License <a
href="https://github.com/codahale/metrics/blob/master/metrics-core/src/main/java/com/yammer/metrics/stats/ExponentiallyDecayingSample.java"
class="external-link"
rel="nofollow">https://github.com/codahale/metrics/blob/master/metrics-core/src/main/java/com/yammer/metrics/stats/ExponentiallyDecayingSample.java</a> 


New Comment: 
I'm a bit concerned that shoehorning latency timings into a long from a double will always
yield zero in a healthy gigabit network where the timings are generally fractional.  But,
there's a good chance in a situation with such similar values their weight is irrelevant
after <a href="https://issues.apache.org/jira/browse/CASSANDRA-3722" title="Send Hints to
Dynamic Snitch when Compaction or repair is going on for a node." class="issue-link"
data-issue-key="CASSANDRA-3722"><del>CASSANDRA-3722</del></a> anyway.Have you done any
profiling to see if this actually is cheaper than the fixed window size?  Specifically I'm
worried about receiveTiming becoming more expensive. 


New Comment: 
<blockquote>Have you done any profiling to see if this actually is cheaper than the fixed
window size? Specifically I'm worried about receiveTiming becoming more
expensive.</blockquote>Yes, I did a few profiling tests and I see ~30 ms degradation in
receiveTiming speed inserting 100000 latency records (increased UPDATES_PER_INTERVAL value
to be fare with the test). 


New Comment: 
<blockquote>Yes, I did a few profiling tests and I see ~30 ms degradation in
receiveTiming</blockquote>This is micros, right? 


New Comment: 
No, it's milliseconds, old one runs in ~80 ms for 100,000 inserts and new one ~109 ms on
the same amount. 


New Comment: 
That's a decent percentage increase, but still 0.001ms/request is pretty minuscule.  LGTM,
+1. 


New Comment: 
How does this affect the math in the original phi accrual failure detector?  Is it worth
getting Paul to look into that? 


New Comment: 
It doesn't, really.  Instead of using a fixed sample size we use a statistically accurate
continuous sample.  The math using the value is the same. 


