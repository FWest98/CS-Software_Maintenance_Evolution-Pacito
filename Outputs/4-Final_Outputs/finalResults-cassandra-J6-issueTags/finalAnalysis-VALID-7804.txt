Pattern changes caused by commit: 110f69c3b857483162c7e86c7ad63061a13dab7f

From: Decorator-2
To:   Decorator-1

From: Facade-0
To:   Facade-1

From: Flyweight-2
To:   Flyweight-1

From: Mediator-3
To:   Mediator-1

From: Strategy-0
To:   Strategy-1


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-7804.txt 

commit 110f69c3b857483162c7e86c7ad63061a13dab7f
Author: Brandon Williams <brandonwilliams@apache.org>

    Remove nodes in total on restart.
    Patch by brandonwilliams, reviewed by Vijay for CASSANDRA-4840



==================================
 Issue CASSANDRA-4840 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-4840] remnants of removed nodes remain after removal
-----------------

-----------------
Summary: remnants of removed nodes remain after removal
-----------------

-----------------
Issue type: Bug
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Fri, 19 Oct 2012 22:28:16 +0000
-----------------

-----------------
Resolved at: Fri, 2 Nov 2012 13:14:50 +0000
-----------------

-----------------
Assigned to: Brandon Williams
-----------------

-----------------
Description: 

After nodes are removed from the ring and no longer appear in any of the nodes' nodetool
ring output, some of the dead nodes show up in the o.a.c.net.FailureDetector SimpleStates
metadata.  Also, some of the JMX stats are updating for the removed nodes (ie
RecentTimeoutsPerHost and ResponsePendingTasks).
 

-----------------

-----------------
Comments: 

New Comment: 
I believe this may be evidence of the issue I've heard reported where nodes are still
trying to connect to dead IPs that were removed.  I suspect a message might be getting
stuck in OTC and causing this.As far as the FD goes, we definitely remove it there in
Gossiper.removeEndpoint, so something must be adding it back. 


New Comment: 
Does this happen in 1.1 as well? 


New Comment: 
Yes, it can happen in 1.1.  Even on restart some kind of message sits in MS for the host
that I haven't tracked down yet.  Worth noting that at least the FD portion is a red
herring, it's dumping the gossiper's endpoint state map which of course contains hosts
with dead state. 


New Comment: 
The gossiper has to notify subscribers of joins, even on dead state.  Specifically it
needs to notify SS in case some action needs to be taken, however SS in turn needs to
notify the gossiper to remove the endpoint if the endpoint is already a non-member.  When
removing an endpoint, the gossiper should notify MS to destroy any conn pools and remove
the timeout tracking.  Patch to do so. 


New Comment: 
Wondering if there might be a race condition since we remove and disconnect should we take
a membership lock on the node and do this? (Not sure if this is a real problem) 


New Comment: 
I'm not sure what you mean, what is a membership lock on the node? 


New Comment: 
Membership lock so no one else add's the node back into the map during the remove
sequence, it would be rare... +1 other than that. 


