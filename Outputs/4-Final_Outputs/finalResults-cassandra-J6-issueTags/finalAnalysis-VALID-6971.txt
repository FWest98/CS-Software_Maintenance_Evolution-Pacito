Pattern changes caused by commit: a4fab90af0063110e1118fb69b9c5923a415b9d3

From: Decorator-2
To:   Decorator-1

From: Flyweight-2
To:   Flyweight-1

From: Mediator-3
To:   Mediator-1

From: Strategy-0
To:   Strategy-1

From: Template Method-3
To:   Template Method-2


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-6971.txt 

commit a4fab90af0063110e1118fb69b9c5923a415b9d3
Author: Jonathan Ellis <jbellis@apache.org>

    avoid promoting tiny sstables
    patch by jbellis; reviewed by yukim for CASSANDRA-4341



==================================
 Issue CASSANDRA-4341 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-4341] Small SSTable Segments Can Hurt Leveling Process
-----------------

-----------------
Summary: Small SSTable Segments Can Hurt Leveling Process
-----------------

-----------------
Issue type: Improvement
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Thu, 14 Jun 2012 16:39:04 +0000
-----------------

-----------------
Resolved at: Fri, 22 Jun 2012 18:16:30 +0000
-----------------

-----------------
Assigned to: Jonathan Ellis
-----------------

-----------------
Description: 

This concerns:

static int MAX_COMPACTING_L0 = 32;

Repair can create very small SSTable
segments. We should consider moving to a threshold that takes into account the size of the
files brought into compaction rather than the number of files for this and similar
situations. Bringing the small files from L0 to L1 magnifies the issue.

If there are too
many very small files in L0 perhaps even an intermediate compaction would even reduce the
magnifying effect of a L0 to L1 compaction.
 

-----------------

-----------------
Comments: 

New Comment: 
<blockquote>Bringing the small files from L0 to L1 magnifies the
issue</blockquote>Meaning, they are so small that even after L0 compaction, what gets
promoted to L1 is also "small?" 


New Comment: 
Patch attached with the following approach:<div class="preformatted panel"
style="border-width: 1px;"><div class="preformattedContent panelContent"><pre>.          
// We treat L0 compactions specially:            // 1a. add sstables to the candidate set
until we have at least maxSSTableSizeInMB            // 1b. prefer choosing older sstables
as candidates, to newer ones            // 1c. any L0 sstables that overlap a candidate,
will also become candidates            // 2. At most MAX_COMPACTING_L0 sstables will be
compacted at once            // 3. If total candidate size is less than
maxSSTableSizeInMB, we won't bother compacting with L1,            //    and the result of
the compaction will stay in L0 instead of being promoted (see promote())</pre></div></div> 


New Comment: 
maxSSTableSizeInMB is, as it says, value in MB. You have to take care when comparing to
sstable's size.<br/>Otherwise, it looks ok. 


New Comment: 
committed w/ MB fixes 


New Comment: 
This patch might make leveled compaction be stuck in an infinite compaction loop if
compaction is used and no more data comes in.The problem is that if you have say 2 sstable
in L0, but those are not bigger than sstableMaxSize, we will compact them in L0 but we
might end up with 2 sstable in L0 instead of 1. Now the reason this can happen is due to
another problem older than this patch. That problem is that when leveled compacts, it
splits sstables at sstableMaxSize of <b>uncompressed</b> data. However LeveledManifest
(the patch on this ticket included) consider the level sizes to be <b>on-disk sizes</b>.
So 2 sstables can be less than 10MB of on-disk size, but when compacting them, they will
still generate 2 sstables because the uncompressed size is &gt; 10 MB.In theory there is 2
possible fixes for that:<ol>	<li>when we compact, consider the on-disk size to split
sstables.</li>	<li>in LeveledManifest, consider level size in uncompressed data size
instead of on-disk size.</li></ol>I think the first solution is closer to the initial
intention in that we want file on disk to be what the user sets with sstableMaxSize.
Besides, doing the 2nd solution means that we would artificially augment the size of all
level, which would make the upgrade a bit painful since it would generate a lot of
compaction to re-equilibrate levels.  So attaching patch that does the first idea. (I note
that because our sequentialWriter buffer data before writing them, getting the on-disk
file pointer give us a position aligned on buffer size, but I don't thing that matters in
that case, except that it makes it an error to have a SequentialWriter buffer size &gt;
compression block size).There was 2 other problem with the committed patch:<ul>	<li>The
edge case where compaction candidates in L0 were exactly of sstableMaxSize was not handled
correctly in that the candidates would not be compacted with L1 sstable but would still be
promoted.</li>	<li>In the case where we had MAX_COMPACTING_L0 candidates, the code wasn't
adding the overlapping sstable from L1.<br/>The attached patch fixes that too.</li></ul> 


New Comment: 
+1, committed 


