Pattern changes caused by commit: 145010997609f1ed8e629b0996c06a367fdde588

From: Abstract Factory-3
To:   Abstract Factory-2

From: Factory Method-3
To:   Factory Method-2

From: Mediator-2
To:   Mediator-1


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-4151.txt 

commit 145010997609f1ed8e629b0996c06a367fdde588
Author: Sylvain Lebresne <slebresne@apache.org>

    Clone super column to avoid modifying them mid-flush
    patch by slebresne; reviewed by jbellis for CASSANDRA-2675



==================================
 Issue CASSANDRA-2675 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-2675] java.io.IOError: java.io.EOFException with version 0.7.6
-----------------

-----------------
Summary: java.io.IOError: java.io.EOFException with version 0.7.6
-----------------

-----------------
Issue type: Bug
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Fri, 20 May 2011 09:09:33 +0000
-----------------

-----------------
Resolved at: Wed, 25 May 2011 15:43:21 +0000
-----------------

-----------------
Assigned to: Sylvain Lebresne
-----------------

-----------------
Description: 

I use the following data-model

column_metadata: []<br/>name: Customers<br/>column_type:
Super<br/>gc_grace_seconds: 60

I have a super-column-family with a single row.<br/>Within
this row I have a single super-column.<br/>Within this super-column, I concurrently
create, read and delete columns.

I have three threads:
<ul class="alternate"
type="square">	<li>Do in a loop: add a column to the super-column.</li>	<li>Do in a loop:
delete a random column from the super-column.</li>	<li>Do in a loop: read the super-column
(with all columns).</li></ul>
After running the above threads concurrently, I always
receive one of the following errors:

ERROR 17:09:57,036 Fatal exception in thread
Thread<span class="error">&#91;ReadStage:81,5,main&#93;</span><br/>java.io.IOError:
java.io.EOFException<br/>        at
org.apache.cassandra.io.util.ColumnIterator.deserializeNext(ColumnSortedMap.java:252)<br/>
       at org.apache.cassandra.io.util.ColumnIterator.next(ColumnSortedMap.java:268)<br/> 
      at org.apache.cassandra.io.util.ColumnIterator.next(ColumnSortedMap.java:227)<br/>  
     at java.util.concurrent.ConcurrentSkipListMap.buildFromSorted(Unknown Source)<br/>   
    at java.util.concurrent.ConcurrentSkipListMap.&lt;init&gt;(Unknown Source)<br/>       
at org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:379)<br/>   
    at
org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:362)<br/>      
 at org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:322)<br/>  
     at
org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:79)<br/>
       at
org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:40)<br/>
       at
com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:136)<br/>
       at
com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131)<br/>       
at
org.apache.cassandra.db.columniterator.SSTableSliceIterator.hasNext(SSTableSliceIterator.java:108)<br/>
       at
org.apache.commons.collections.iterators.CollatingIterator.set(CollatingIterator.java:283)<br/>
       at
org.apache.commons.collections.iterators.CollatingIterator.least(CollatingIterator.java:326)<br/>
       at
org.apache.commons.collections.iterators.CollatingIterator.next(CollatingIterator.java:230)<br/>
       at
org.apache.cassandra.utils.ReducingIterator.computeNext(ReducingIterator.java:69)<br/>    
   at
com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:136)<br/>
       at
com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131)<br/>       
at
org.apache.cassandra.db.filter.SliceQueryFilter.collectReducedColumns(SliceQueryFilter.java:116)<br/>
       at
org.apache.cassandra.db.filter.QueryFilter.collectCollatedColumns(QueryFilter.java:130)<br/>
       at
org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1390)<br/>
       at
org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1267)<br/>
       at
org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1195)<br/>
       at org.apache.cassandra.db.Table.getRow(Table.java:324)<br/>        at
org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:63)<br/>    
   at
org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:451)<br/>
       at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)<br/>    
   at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)<br/>       
at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)<br/>        at
java.lang.Thread.run(Unknown Source)<br/>Caused by: java.io.EOFException<br/>        at
java.io.RandomAccessFile.readByte(Unknown Source)<br/>        at
org.apache.cassandra.utils.ByteBufferUtil.readShortLength(ByteBufferUtil.java:324)<br/>   
    at
org.apache.cassandra.utils.ByteBufferUtil.readWithShortLength(ByteBufferUtil.java:335)<br/>
       at
org.apache.cassandra.db.ColumnSerializer.deserialize(ColumnSerializer.java:71)<br/>       
at
org.apache.cassandra.io.util.ColumnIterator.deserializeNext(ColumnSortedMap.java:248)<br/>
       ... 30 more

java.io.IOError:
org.apache.cassandra.db.ColumnSerializer$CorruptColumnException: invalid column name
length 0<br/>        at
org.apache.cassandra.io.util.ColumnIterator.deserializeNext(ColumnSortedMap.java:252)<br/>
       at org.apache.cassandra.io.util.ColumnIterator.next(ColumnSortedMap.java:268)<br/> 
      at org.apache.cassandra.io.util.ColumnIterator.next(ColumnSortedMap.java:227)<br/>  
     at java.util.concurrent.ConcurrentSkipListMap.buildFromSorted(Unknown Source)<br/>   
    at java.util.concurrent.ConcurrentSkipListMap.&lt;init&gt;(Unknown Source)<br/>       
at org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:379)<br/>   
    at
org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:362)<br/>      
 at org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:322)<br/>  
     at
org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:79)<br/>
       at
org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:40)<br/>
       at
com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:136)<br/>
       at
com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131)<br/>       
at
org.apache.cassandra.db.columniterator.SSTableSliceIterator.hasNext(SSTableSliceIterator.java:108)<br/>
       at
org.apache.commons.collections.iterators.CollatingIterator.set(CollatingIterator.java:283)<br/>
       at
org.apache.commons.collections.iterators.CollatingIterator.least(CollatingIterator.java:326)<br/>
       at
org.apache.commons.collections.iterators.CollatingIterator.next(CollatingIterator.java:230)<br/>
       at
org.apache.cassandra.utils.ReducingIterator.computeNext(ReducingIterator.java:69)<br/>    
   at
com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:136)<br/>
       at
com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131)<br/>       
at
org.apache.cassandra.db.filter.SliceQueryFilter.collectReducedColumns(SliceQueryFilter.java:116)<br/>
       at
org.apache.cassandra.db.filter.QueryFilter.collectCollatedColumns(QueryFilter.java:130)<br/>
       at
org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1385)<br/>
       at
org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1262)<br/>
       at
org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1190)<br/>
       at org.apache.cassandra.db.Table.getRow(Table.java:324)<br/>        at
org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:63)<br/>    
   at
org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:451)<br/>
       at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)<br/>    
   at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)<br/>       
at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)<br/>        at
java.lang.Thread.run(Unknown Source)<br/>Caused by:
org.apache.cassandra.db.ColumnSerializer$CorruptColumnException: invalid column name
length 0<br/>        at
org.apache.cassandra.db.ColumnSerializer.deserialize(ColumnSerializer.java:73)<br/>       
at
org.apache.cassandra.io.util.ColumnIterator.deserializeNext(ColumnSortedMap.java:248)<br/>
       ... 30 more 

ERROR 11:02:19,824 Fatal exception in thread Thread<span
class="error">&#91;ReadStage:3404,5,main&#93;</span><br/>java.io.IOError:
java.io.IOException: mmap segment underflow; remaining is 660267 but 758592100
requested<br/>	at
org.apache.cassandra.io.util.ColumnIterator.deserializeNext(ColumnSortedMap.java:252)<br/>	at
org.apache.cassandra.io.util.ColumnIterator.next(ColumnSortedMap.java:268)<br/>	at
org.apache.cassandra.io.util.ColumnIterator.next(ColumnSortedMap.java:227)<br/>	at
java.util.concurrent.ConcurrentSkipListMap.buildFromSorted(Unknown Source)<br/>	at
java.util.concurrent.ConcurrentSkipListMap.&lt;init&gt;(Unknown Source)<br/>	at
org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:379)<br/>	at
org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:362)<br/>	at
org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:322)<br/>	at
org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:79)<br/>	at
org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:40)<br/>	at
com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:136)<br/>	at
com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131)<br/>	at
org.apache.cassandra.db.columniterator.SSTableSliceIterator.hasNext(SSTableSliceIterator.java:108)<br/>	at
org.apache.commons.collections.iterators.CollatingIterator.set(CollatingIterator.java:283)<br/>	at
org.apache.commons.collections.iterators.CollatingIterator.least(CollatingIterator.java:326)<br/>	at
org.apache.commons.collections.iterators.CollatingIterator.next(CollatingIterator.java:230)<br/>	at
org.apache.cassandra.utils.ReducingIterator.computeNext(ReducingIterator.java:69)<br/>	at
com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:136)<br/>	at
com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131)<br/>	at
org.apache.cassandra.db.filter.SliceQueryFilter.collectReducedColumns(SliceQueryFilter.java:116)<br/>	at
org.apache.cassandra.db.filter.QueryFilter.collectCollatedColumns(QueryFilter.java:130)<br/>	at
org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1390)<br/>	at
org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1267)<br/>	at
org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1195)<br/>	at
org.apache.cassandra.db.Table.getRow(Table.java:324)<br/>	at
org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:63)<br/>	at
org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:451)<br/>	at
org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)<br/>	at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)<br/>	at
java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)<br/>	at
java.lang.Thread.run(Unknown Source)
 

-----------------

-----------------
Comments: 

New Comment: 
Test application (.NET 4) to reproduce problem 


New Comment: 
Included the Java version of the test program.Usage:java -jar CassandraIssue.jar
[&lt;ip&gt; [&lt;keyspace&gt; [&lt;column-family&gt; <span
class="error">&#91;&lt;port&gt;&#93;</span>]]] 


New Comment: 
I was able to reproduce, thanks for the java version.I think the problem is that reads can
remove subcolumns from a super-column that happens to be in a memtable being flushed. If a
subcolumn become gc-able after when the super column count size was written on disk and
the time the subcolumn itself is written we won't write it and will end up with short
super columns (hence the EOFException). Note that this should not happen with a reasonable
gc_grace value (one such that nothing that gets flushed will be gcable).First attached
patch fixes this by making reads copy the super-column before modifying it (0.7 patch).I
think there is a related second bug, in that when we reduce super columns (in
QueryFilter), if we merge multiple super column with the same name, we'll "merge" them in
the first super column. That is, we may end up adding subcolumns to a super column that is
in an in-memory memtable. Most of the time this will be harmless, except some useless data
duplication. But if that happens for a super column (in a memtable) being flushed and, as
above, between the write of the number of column and the actual column writes, we may end
up with too long super column. With could result in unreachable columns (i.e, data loss
effectively) and quite probably some weird corruption during a compaction.Second patch
fixes this second problem.I haven't been able to reproduce with the 2 attached patches and
the thing is running since more than an hour. 


New Comment: 
does the copyOnWrite optimization in patch 1 make sense, given that patch 2 will do a copy
anyway?  might be simpler to just force the copy in getCF so any higher-level callers
don't have to worry about it. 


New Comment: 
Yes I agree, patch 2 is actually enough. 


New Comment: 
Is it?  Don't you still have the problem of a tombstone cleanup modifying things
mid-flush?I was thinking patch 1 modified to always-copy would be enough but there is
actually an efficiency gain when you don't have multiple CF/SC merging, so +1 on both if I
understand correctly.Nit: would prefer to expose a CF.isEmpty method than make column size
public &#8211; CSLM.size is O(N) and while that doesn't matter here it would be easy to
introduce inefficiency w/o realizing it. 


New Comment: 
<blockquote>Is it? Don't you still have the problem of a tombstone cleanup modifying
things mid-flush?</blockquote>Patch 2 make sure that the cf returned by a
getTopLevelColumns() doesn't have any super column that is an alias of a super column in
some memtable. So then we don't care what consumers of the result getTopLevelColumns() do.
Even if they remove columns the 'being flushed' super column won't be affected.The idea of
not always copying in the first patch was to not incure the copy to all the part of the
code that doesn't care (mainly compaction). But anyway, I do think that patch 2 is
enough.Attaching v2 of patch 2 to use isEmpty. 


New Comment: 
+1 


New Comment: 
Integrated in Cassandra-0.7 #496 (See <a
href="https://builds.apache.org/hudson/job/Cassandra-0.7/496/" class="external-link"
rel="nofollow">https://builds.apache.org/hudson/job/Cassandra-0.7/496/</a>)<br/>    Clone
super column to avoid modifying them mid-flush<br/>patch by slebresne; reviewed by jbellis
for <a href="https://issues.apache.org/jira/browse/CASSANDRA-2675" title="java.io.IOError:
java.io.EOFException with version 0.7.6" class="issue-link"
data-issue-key="CASSANDRA-2675"><del>CASSANDRA-2675</del></a>slebresne : <a
href="http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;view=rev&amp;rev=1127130"
class="external-link"
rel="nofollow">http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;view=rev&amp;rev=1127130</a><br/>Files
:
<ul>	<li>/cassandra/branches/cassandra-0.7/CHANGES.txt</li>	<li>/cassandra/branches/cassandra-0.7/src/java/org/apache/cassandra/db/ColumnFamily.java</li>	<li>/cassandra/branches/cassandra-0.7/src/java/org/apache/cassandra/db/filter/QueryFilter.java</li></ul> 


