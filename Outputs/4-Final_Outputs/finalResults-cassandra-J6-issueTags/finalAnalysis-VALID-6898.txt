Pattern changes caused by commit: 1d9b7f5597f2cd090e312e270431ab56c81de9d9

From: Decorator-2
To:   Decorator-1

From: Flyweight-2
To:   Flyweight-1

From: Mediator-3
To:   Mediator-1

From: Strategy-0
To:   Strategy-1

From: Template Method-3
To:   Template Method-2


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-6898.txt 

commit 1d9b7f5597f2cd090e312e270431ab56c81de9d9
Author: Pavel Yaskevich <xedin@apache.org>

    Try to stop all compaction upon Keyspace or ColumnFamily drop
    patch by Pavel Yaskevich; reviewed by Jonathan Ellis for CASSANDRA-4221



==================================
 Issue CASSANDRA-4221 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-4221] Error while deleting a columnfamily that is being compacted.
-----------------

-----------------
Summary: Error while deleting a columnfamily that is being compacted.
-----------------

-----------------
Issue type: Bug
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Fri, 4 May 2012 13:23:48 +0000
-----------------

-----------------
Resolved at: Mon, 28 May 2012 18:26:32 +0000
-----------------

-----------------
Assigned to: Pavel Yaskevich
-----------------

-----------------
Description: 

The following dtest command produces an error:
<div class="code panel"
style="border-width: 1px;"><div class="codeContent panelContent"><pre
class="code-java">export CASSANDRA_VERSION=git:cassandra-1.1; nosetests --nocapture
--nologcapture
concurrent_schema_changes_test.py:TestConcurrentSchemaChanges.load_test</pre></div></div>
Here
is the error:
<div class="code panel" style="border-width: 1px;"><div class="codeContent
panelContent"><pre class="code-java">Error occured during
compactionjava.util.concurrent.ExecutionException: java.io.IOError:
java.io.FileNotFoundException:
/tmp/dtest-6ECMgy/test/node1/data/Keyspace1/Standard1/Keyspace1-Standard1-hc-47-Data.db
(No such file or directory)	at
java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)	at
java.util.concurrent.FutureTask.get(FutureTask.java:111)	at
org.apache.cassandra.db.compaction.CompactionManager.performMaximal(CompactionManager.java:239)	at
org.apache.cassandra.db.ColumnFamilyStore.forceMajorCompaction(ColumnFamilyStore.java:1580)	at
org.apache.cassandra.service.StorageService.forceTableCompaction(StorageService.java:1770)	at
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)	at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)	at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)	at
java.lang.reflect.Method.invoke(Method.java:616)	at
com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:111)	at
com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:45)	at
com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:226)	at
com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)	at
com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:251)	at
com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:857)	at
com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:795)	at
javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1450)	at
javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:90)	at
javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1285)	at
javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1383)	at
javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:807)	at
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)	at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)	at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)	at
java.lang.reflect.Method.invoke(Method.java:616)	at
sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:322)	at
sun.rmi.transport.Transport$1.run(Transport.java:177)	at
java.security.AccessController.doPrivileged(Native Method)	at
sun.rmi.transport.Transport.serviceCall(Transport.java:173)	at
sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:553)	at
sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:808)	at
sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:667)	at
java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)	at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)	at
java.lang.<span class="code-object">Thread</span>.run(<span
class="code-object">Thread</span>.java:679)Caused by: java.io.IOError:
java.io.FileNotFoundException:
/tmp/dtest-6ECMgy/test/node1/data/Keyspace1/Standard1/Keyspace1-Standard1-hc-47-Data.db
(No such file or directory)	at
org.apache.cassandra.io.sstable.SSTableScanner.&lt;init&gt;(SSTableScanner.java:61)	at
org.apache.cassandra.io.sstable.SSTableReader.getDirectScanner(SSTableReader.java:839)	at
org.apache.cassandra.io.sstable.SSTableReader.getDirectScanner(SSTableReader.java:851)	at
org.apache.cassandra.db.compaction.AbstractCompactionStrategy.getScanners(AbstractCompactionStrategy.java:142)	at
org.apache.cassandra.db.compaction.AbstractCompactionStrategy.getScanners(AbstractCompactionStrategy.java:148)	at
org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:121)	at
org.apache.cassandra.db.compaction.CompactionManager$6.runMayThrow(CompactionManager.java:264)	at
org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)	at
java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)	at
java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)	at
java.util.concurrent.FutureTask.run(FutureTask.java:166)	... 3 moreCaused by:
java.io.FileNotFoundException:
/tmp/dtest-6ECMgy/test/node1/data/Keyspace1/Standard1/Keyspace1-Standard1-hc-47-Data.db
(No such file or directory)	at java.io.RandomAccessFile.open(Native Method)	at
java.io.RandomAccessFile.&lt;init&gt;(RandomAccessFile.java:233)	at
org.apache.cassandra.io.util.RandomAccessReader.&lt;init&gt;(RandomAccessReader.java:67)	at
org.apache.cassandra.io.util.RandomAccessReader.open(RandomAccessReader.java:102)	at
org.apache.cassandra.io.util.RandomAccessReader.open(RandomAccessReader.java:87)	at
org.apache.cassandra.io.sstable.SSTableReader.openDataReader(SSTableReader.java:985)	at
org.apache.cassandra.io.sstable.SSTableScanner.&lt;init&gt;(SSTableScanner.java:56)	... 13
more</pre></div></div>
For reference, here is the dtest function that causes the failure.
The error happens on the line near the bottom that drops the columnfamily:
<div
class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"><pre
class="code-java">    def load_test(self):                                                
               """                                                                        
    apply schema changes <span class="code-keyword">while</span> the cluster is under
load.                           """                                                       
                     debug(<span class="code-quote">"load_test()"</span>)                 
                                                                                          
                               cluster = self.cluster                                     
                    cluster.populate(1).start()                                           
         node1 = cluster.nodelist()[0]                                                  
wait(2)                                                                         cursor =
self.cql_connection(node1).cursor()                                                       
                                                            def stress(args=[]):          
                                                     debug(<span
class="code-quote">"Stressing"</span>)                                                    
         node1.stress(args)                                                             
debug(<span class="code-quote">"Done Stressing"</span>)                                   
                                                                                          
      def compact():                                                                     
debug(<span class="code-quote">"Compacting..."</span>)                                    
                     node1.nodetool(<span class="code-quote">'compact'</span>)            
                                          debug(<span class="code-quote">"Done
Compacting."</span>)                                                                      
                                                            # put some data into the
cluster                                                stress([<span
class="code-quote">'--num-keys=1000000'</span>])                                          
                                                                                       #
now start compacting...                           tcompact = <span
class="code-object">Thread</span>(target=compact)                                         
     tcompact.start()                                                               
wait(1)                                                                                   
                                                                     # now the cluster is
under a lot of load. Make some schema changes.             cursor.execute(<span
class="code-quote">"USE Keyspace1"</span>)                                                
wait(1)                                                                        
cursor.execute(<span class="code-quote">"DROP COLUMNFAMILY Standard1"</span>)             
                                                                                          
          wait(3)                                                                         
                                                                              
cursor.execute(<span class="code-quote">"CREATE COLUMNFAMILY Standard1 (KEY text PRIMARY
KEY)"</span>)                                                                             
            tcompact.join()                                                         
</pre></div></div>
Again, the error happens on cassandra-1.1, but not on cassandra-1.0.
 

-----------------

-----------------
Comments: 

New Comment: 
This one seems to be caused by the same problem as <a
href="https://issues.apache.org/jira/browse/CASSANDRA-4230" title="Deleting a CF always
produces an error and that CF remains in an unknown state" class="issue-link"
data-issue-key="CASSANDRA-4230"><del>CASSANDRA-4230</del></a>. 


New Comment: 
Maybe, but I'm skeptical &#8211; 4230 is complaining about a file existing when it
shouldn't, while this one says a file doesn't exist that should <img class="emoticon"
src="https://issues.apache.org/jira/images/icons/emoticons/smile.png" height="16"
width="16" align="absmiddle" alt="" border="0"/> 


New Comment: 
Patch adds a try to stop all running compactions on given Keyspace or ColumnFamily before
running a drop command. I have tried the test you have in the description and it ran
without failures. 


New Comment: 
That takes us back to the Bad Old Days pre-<a
href="https://issues.apache.org/jira/browse/CASSANDRA-3116" title="Compactions can
(seriously) delay schema migrations" class="issue-link"
data-issue-key="CASSANDRA-3116"><del>CASSANDRA-3116</del></a>, though.  We should be able
to fix w/o resorting to A Big Lock. 


New Comment: 
For the KS or CF drop this seems necessary to try to wait until all running compactions
finish otherwise it would end up in errors like one in the description, also other
operations - create, update - are not affected by this. 


New Comment: 
The idea from 3116 was:<ul class="alternate" type="square">	<li>Drop will only delete
sstables not actively being compacted</li>	<li>post-compaction, we check if the CF was
dropped, and if so we delete the sstables then</li></ul> 


New Comment: 
I don't know which one is better tho because if compaction fails for some reason which
that scenario, wouldn't that mean that all SSTables that were left behind are staying
until somebody manually deletes them (or restart would drop them)? We would have to add
complexity to the schema merge just to handle that case as well as on the local side... 


New Comment: 
The other way would be to 'mark a CF for delete' and return to the user right way (making
CF invisible to users), sending the drop request to the others where they would apply the
same thing (try to stop all compactions running, wait until they are done) and drop. 


New Comment: 
<blockquote>wouldn't that mean that all SSTables that were left behind are staying until
somebody manually deletes them (or restart would drop them)? </blockquote>We already clean
up partially-written sstables after compaction failure, I don't see why we couldn't use
similar logic here. 


New Comment: 
The problem I see that that is we need to do a snapshot before start dropping or deleting
any CF files so it's probably better to make that drop option 'deferred' until running
compactions are stopped so we have a persistent view of the files we would have to operate
upon. 


New Comment: 
DataTracker already makes sstable changes atomic, though.  At any time you can snapshot
with that and get a consistent view. 


New Comment: 
Tyler, can you still reproduce after the recent schema fixes on the 1.1 branch? 


New Comment: 
Yes, the error just happened again for me. I did a fresh pull on branch branch
cassandra-1.1. 


New Comment: 
Interesting, I can't reproduce it myself. Can you please run it with logging patch
attached (and enabled DEBUG logging) and attach debug log from your C* node to this task,
so I can check that is happening inside of DataTracker in your case?... 


New Comment: 
This was after applying both patches to the cassandra-1.1 branch, and setting logging to
DEBUG. 


New Comment: 
Somehow that server.log did not have the debug info. Looking into it now. 


New Comment: 
Debug is enabled now; It looks like CCM overwrites the log level. Only the logging patch
was applied in this run. 


New Comment: 
I see debug information I added right now, but there is no IOError in that log described
in this task... 


New Comment: 
So after some experimentation, the problem is only happening when the log level is set to
INFO, but it doesn't happen at DEBUG. Gotta love these ones! I modified the logging patch
to do logging.info() rather then logging.debug(), and the problem still happens, so at
least you can see those debug messages. I hope this is enough to go on. 


New Comment: 
Hah, now I know what is causing it - it's not a drop problem, the situation is triggered
when you re-create ColumnFamily right after drop <ins>(before all SSTables were actually
deleted by background task)</ins> so it reads up all SSTables in the directory back to
system and tries to compact them simultaneously with them being deleted in the background.
That is why we warn people to <b>avoid</b> making any modifications to the active CFs
otherwise it could lead to the strange situations like this one. 


New Comment: 
Would this be fixed by <a href="https://issues.apache.org/jira/browse/CASSANDRA-3794"
title="Avoid ID conflicts from concurrent schema changes" class="issue-link"
data-issue-key="CASSANDRA-3794"><del>CASSANDRA-3794</del></a> then, since old and new CF
will have different IDs? 


New Comment: 
Not really because it generates UUID from ksName + cfName to be able make it the same
across all machines independent of their state. 


New Comment: 
Should we just add a call to abort in-progress compactions at drop time (which will help
cleanup happen faster) and call that "as close as we're going to get?" 


New Comment: 
This is what I did in my patch <img class="emoticon"
src="https://issues.apache.org/jira/images/icons/emoticons/smile.png" height="16"
width="16" align="absmiddle" alt="" border="0"/> 


New Comment: 
<ul class="alternate" type="square">	<li>stopCompactionFor should take CFS parameters
instead of String</li>	<li>I don't see any reason to not wait indefinitely here; in fact,
if we make sure to wait until compaction finishes, the odds are much better that when we
tell the client "all done" he won't be able to send a "create" quickly enough to hit the
bug</li>	<li>Need to call stopCompactionFor on every replica, not just CompactionServer
&#8211; move this to DefsTable.dropColumnFamily?</li></ul> 


New Comment: 
<blockquote>stopCompactionFor should take CFS parameters instead of String</blockquote>I
don't really follow here, if you want it to have list of CFMetaData instead of String?
String is better suited because CompactionInfo.getColumnFamily() returns a String (CF
name).<blockquote>I don't see any reason to not wait indefinitely here; in fact, if we
make sure to wait until compaction finishes, the odds are much better that when we tell
the client "all done" he won't be able to send a "create" quickly enough to hit the
bug</blockquote>We don't really try to wait indefinitely here, just for 30 seconds (worst
case), if compactions don't finish until then we just move on with delete. do you want it
to wait until all compactions  to finish?<blockquote>Need to call stopCompactionFor on
every replica, not just CompactionServer – move this to
DefsTable.dropColumnFamily?</blockquote>I agree, I'm going to move that into
dropColumnFamily call so it gets called on the replicas too. 


New Comment: 
<blockquote>String is better suited because CompactionInfo.getColumnFamily() returns a
String </blockquote>Feel free to fix that. <img class="emoticon"
src="https://issues.apache.org/jira/images/icons/emoticons/smile.png" height="16"
width="16" align="absmiddle" alt="" border="0"/><blockquote>if compactions don't finish
until then we just move on with delete</blockquote>It throws IOException.Remember that we
check for ability to abort compaction every row; if we're compacting a wide row, it could
easily take over 30s w/ throttling. 


New Comment: 
<blockquote>It throws IOException. Remember that we check for ability to abort compaction
every row; if we're compacting a wide row, it could easily take over 30s w/
throttling.</blockquote>Oh yes, sorry. I think we can just remove that exception and move
on with drop, or do you want it to until all compactions finish? 


New Comment: 
v3 attached.  removes CompactionInfo fields that are redundant w/ the introduction of CFM,
and removes the wait from the stop method (it doesn't help clean up the sstables involved
any faster, so there is no point in slowing down the drop for it). 


