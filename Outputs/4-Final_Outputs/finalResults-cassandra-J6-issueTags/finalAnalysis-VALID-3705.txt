Pattern changes caused by commit: 80d3decdfe70b12422c24cd71405aecc5a02b97e

From: Abstract Factory-2
To:   Abstract Factory-3

From: Factory Method-2
To:   Factory Method-3

From: Mediator-1
To:   Mediator-2


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-3705.txt 

commit 80d3decdfe70b12422c24cd71405aecc5a02b97e
Author: Jonathan Ellis <jbellis@apache.org>

    add SerializingCacheProvider
    patch by Vijay and jbellis for CASSANDRA-1969



==================================
 Issue CASSANDRA-1969 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-1969] Use BB for row cache - To Improve GC performance.
-----------------

-----------------
Summary: Use BB for row cache - To Improve GC performance.
-----------------

-----------------
Issue type: Improvement
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Tue, 11 Jan 2011 22:06:15 +0000
-----------------

-----------------
Resolved at: Wed, 6 Apr 2011 18:16:53 +0000
-----------------

-----------------
Assigned to: Vijay
-----------------

-----------------
Description: 

Java BB.allocateDirect() will allocate native memory out of the JVM and will help
reducing the GC pressure in the JVM with a large Cache.<br/>From some of the basic tests
it shows around 50% improvement than doing a normal Object cache.

In addition this patch
provide the users an option to choose BB.allocateDirect or store everything in the heap.
 

-----------------

-----------------
Comments: 

New Comment: 
POC code attached. 


New Comment: 
I am highly in favor of this. +1. This will allow us to separate thread pools on the read
path. 1 pool for serving up cached reads, the other for serving up dedicated reads to
disk. This is how InnoDB does it. We would no longer have to rely on page cache. 


New Comment: 
Vijay I'm not sure I understand your graphs.  By "50% improvement" do you mean that less
heap space is used?  Not that reads or write to the cache are faster, or that less total
memory is used? 


New Comment: 
i would expect reads to be substantially slower if you're deserializing the entire row
from the ByteBuffer.writes would be even worse since you have to deserialize, merge,
reserialize (or maybe it's better to just invalidate the row and re-cache it for the next
read, at that point). 


New Comment: 
Chris Burroughs: i mean while doing a GC (With the same data set), specially with
ConcurrentMarkSweep... thats expected as the bytes[] from BB.allocateDirect() is not
GC'ed, Yes it is also because of smaller heap size.Reads will be a little slower but this
is a good tradeoff if we have a huge Cache.... (For smaller cache we might choose to have
the existing cache). 


New Comment: 
Update:Reclaiming the space of the invalid cache objects gets complicated.... running OOM
(Native) is not within the GC control (until a full GC runs on the JVM automatically, free
space are not automatically/manually reclaimed), and I couldn't find a clean way to free
the native memory from Java. Option 1 (Easier option): Set a hard limit on the Native
memory which can be allocated by the GC once it is full, load the Objects in cache in the
Heap Memory. Eventually the cache will be cleaned by GC (always staying within 2 limits
hard- total objects cached and soft - total objects which can be cached in the
heap).Option 2: Allocate chunks of memory in the native memory and reclame it when they
are needed. Example: when you need 25.5 K block always allocate 26K block and once it is
free allocate a new Object which is of the same size into the cache (This is only if GC
didn't reclaim the object, if reclaimed by GC reassign memory native), this can be done
using PhantomReference, 'if' enqued then allocate new 'else' use the same block of memory. 


New Comment: 
<blockquote>I couldn't find a clean way to free the native memory from Java</blockquote>I
was working on <a href="https://issues.apache.org/jira/browse/CASSANDRA-1255"
title="Explore interning keys and column names" class="issue-link"
data-issue-key="CASSANDRA-1255"><del>CASSANDRA-1255</del></a> and thinking of extending it
to push column values into a DirectBB, and was just starting to think about that
problem.Basically it boils down to re-implementing GC at the user level, I think. 


New Comment: 
"Basically it boils down to re-implementing GC at the user level, I think."Or keeping the
JVM smaller and waiting for the GC to cleanup.... I am not sure, but it might work for
cache.... The problem which i have currently is having the cache invalidate... Currently
we get it from cache (For writes) and start working on that object directly this works for
the object cache... but this might not work for BB cache... hence we might need to add a
invalidation method. 


New Comment: 
Yes, for non-heap cache you want to just drop updated rows from the cache and let it be
re-populated on the next read. 


New Comment: 
Attached Patch... passes system test... And verified functionality. 


New Comment: 
Test case 


New Comment: 
Attached another approach in two patches:01: introduce ICache, InstrumentingCache,
IRowCacheProviderThis takes the JMX instrumentation and moves it into a wrapper class
(InstrumentingCache) so we don't need to re-implement that for each cache.  Then we make
the row cache interface pluggable with IRowCacheProvider.02: implement
SerializingCacheTrying to implement off-heap caching with allocateDirect is messy; the
original approach is going to fragment quickly, and allocation is O(N) in the number of
freed chunks.  (I think there may also be a leak since there is no eviction listener on
the CLHM.)  This is a problem that malloc already solves, so SerializingCache uses
FreeingMemory, derived from jna Memory, to access malloc/free directly.I left out anything
based on EHCache; as described in <a
href="https://issues.apache.org/jira/browse/CASSANDRA-1945" title="Use EHcache for row
cache + disk spillover" class="issue-link"
data-issue-key="CASSANDRA-1945"><del>CASSANDRA-1945</del></a> the performance penalty from
using JDK serialization is prohibitive.TODO: <ul class="alternate" type="square">	<li>(for
this ticket) specifying cache provider in the CF definition</li>	<li>(for another ticket)
adding a deserialize(ByteBuffer) method to ColumnFamilySerializer to avoid copies (using
BB.duplicate for column names and values)</li></ul> 


New Comment: 
Thanks Jonathan, This indeed looks cleaner than allocateDirect.... wasnt aware of
jna.Memory earlier.... Regarding "and allocation is O(N)" &#8212; It provides O(1) as it
is backed by Queue and HashMap (which can have maximum of Integer.Max elements in HM) ...
the idea was to reduce the number of operations while write..... With the assumption that
the GC will cleanup the WeekReference immediately, and wont grow or fragment.... +1 for
Jonathan's approach.... 


New Comment: 
The problem was that WeakReferences are only cleaned up in full collections (CMS or STW),
so if GC is tuned correctly you won't be seeing that happen much, and you'll be doing a
lot of queue iterations. 


New Comment: 
Attached 0003 which adds ICache.isCopying &#8211; if true, it skips calling localCopy
before sending to the cache (and invalidates rows on update instead of deser + update +
ser).  0003 applies on top of <a
href="https://issues.apache.org/jira/browse/CASSANDRA-1255" title="Explore interning keys
and column names" class="issue-link"
data-issue-key="CASSANDRA-1255"><del>CASSANDRA-1255</del></a> 


New Comment: 
Hi Jonathan,1) Can We catch for OOM when creating direct memory? and log it and return
null so it is not affecting the normal operations?<br/>2) Can we add a JVM parameter to
limit the JVM direct memory allocations (Which will include the allocations for Page
Cache)? 


New Comment: 
1) done in new 0002.2) We can open another ticket to change row cache sizing options; for
now, let's leave it configured in number of rows.  We do zero other direct memory
allocations. 


New Comment: 
Fixed, concurrency issue in BB deserialize and added null check in V2 


New Comment: 
Hmm, I can't apply 0002-V2 on top of either my 0001 + trunk from feb 5, or current trunk +
rebased 0001.  And Eclipse generates the diff in a different order from git commandline,
so I can't tell what's changed by eyeballing the diff either.I've attached
rebased-to-current-trunk versions of my 0001-0003, can you attach your fixes as a 0004 on
top of those? 


New Comment: 
ahaa, hope git works! 


New Comment: 
Adds row_cache_provider to CFMetaData. <br/>When it's coming in via YAML/thrift/avro, it's
a string. It then creates an IRowCacheProvider in FBUtils like IPartitioner, et al.Doesn't
handle changes at runtime, but a new ticket should be opened for that. 


New Comment: 
JNA 3.2.7 can cause segfaults when manual free-ing of Memory objects is attempted this
way.  This is fixed in <a href="http://java.net/jira/browse/JNA-179" class="external-link"
rel="nofollow">http://java.net/jira/browse/JNA-179</a> but who knows when that will be in
an actual release.  allocateDirect (with -XX:MaxDirectMemorySize) is the standard way to
do this...  but the code does not fill me with confidence.  Here is Bits.reserveMemory,
which is called by DirectByteBuffer constructor:<div class="code panel"
style="border-width: 1px;"><div class="codeContent panelContent"><pre
class="code-java">	<span class="code-keyword">synchronized</span> (Bits.class) {	    <span
class="code-keyword">if</span> (!memoryLimitSet &amp;&amp; VM.isBooted()) {		maxMemory =
VM.maxDirectMemory();		memoryLimitSet = <span class="code-keyword">true</span>;	    }	   
<span class="code-keyword">if</span> (size &lt;= maxMemory - reservedMemory)
{		reservedMemory += size;		<span class="code-keyword">return</span>;	    }	}	<span
class="code-object">System</span>.gc();	<span class="code-keyword">try</span> {	    <span
class="code-object">Thread</span>.sleep(100);	} <span class="code-keyword">catch</span>
(InterruptedException x) {	    <span class="code-comment">// Restore interrupt
status</span>	    <span
class="code-object">Thread</span>.currentThread().interrupt();	}	<span
class="code-keyword">synchronized</span> (Bits.class) {	    <span
class="code-keyword">if</span> (reservedMemory + size &gt; maxMemory)		<span
class="code-keyword">throw</span> <span class="code-keyword">new</span>
OutOfMemoryError(<span class="code-quote">"Direct buffer memory"</span>);	   
reservedMemory += size;	}</pre></div></div>So if it hits the ceiling it tries to GC but if
it hasn't finished GC in 100ms then it will OOM.  I don't think I've ever seen a CMS GC
finish in 100ms (maybe this was intended for the STW GC?) so that's not very
helpful.Leaning towards switching to ordinary (i.e. no manual free) JNA Memory + a hint
for when to GC w/o the problems of reservedMemory. 


New Comment: 
I also hit <a href="http://java.net/jira/browse/JNA-180" class="external-link"
rel="nofollow">http://java.net/jira/browse/JNA-180</a> while testing #2167 and it is fixed
in jna trunk... Can we just build the trunk and use it? 


New Comment: 
In <a href="https://issues.apache.org/jira/browse/CASSANDRA-2252" title="arena allocation
for memtables" class="issue-link"
data-issue-key="CASSANDRA-2252"><del>CASSANDRA-2252</del></a>, we catch allocation
failures for direct buffers and allocate on heap instead with a logged warning. IMO this
is probably a sufficient solution for "has not been gc'd yet": we've never hit the failed
allocation codepath at all. 


New Comment: 
<blockquote>it is fixed in jna trunk... Can we just build the trunk and use
it?</blockquote>That's not very useful for most people, since we can't distributed JNA as
part of Cassandra.  "Now go build JNA from trunk" isn't part of install instructions
people like to see. <img class="emoticon"
src="https://issues.apache.org/jira/images/icons/emoticons/smile.png" height="16"
width="16" align="absmiddle" alt="" border="0"/><blockquote>we've never hit the failed
allocation codepath at all</blockquote>how big is your MaxDirectMemorySize?  if you're not
setting it at all then there is no limit and you'll just start swapping (if that's
enabled). 


New Comment: 
Are you sure MaxDirectMemorySize by default is unlimited? I remember seeing the default
was 64MB.. 


New Comment: 
"Are you sure MaxDirectMemorySize by default is unlimited? I remember seeing the default
was 64MB"Yes by default it is unlimited and it includes page cache (MMAP) and other direct
allocations. 


New Comment: 
Maybe I am missing something...// A user-settable upper limit on the maximum amount of
allocatable direct<br/>// buffer memory.  This value may be changed during VM
initialization if<br/>// "java" is launched with
"-XX:MaxDirectMemorySize=&lt;size&gt;".<br/>//<br/>// The initial value of this field is
arbitrary; during JRE initialization<br/>// it will be reset to the value specified on the
command line, if any,<br/>// otherwise to
Runtime.getRuntime.maxDirectMemory().<br/>//<br/>private static long directMemory = 64 *
1024 * 1024;// If this method is invoked during VM initialization, it initializes
the<br/>// maximum amount of allocatable direct buffer memory (in bytes) from the<br/>//
system property sun.nio.MaxDirectMemorySize.  The system property will<br/>// be removed
when it is accessed.<br/>//<br/>// If this method is invoked after the VM is booted, it
returns the<br/>// maximum amount of allocatable direct buffer memory. public static long
maxDirectMemory() {<br/>       if (booted)<br/>           return directMemory;      
Properties p = System.getProperties();<br/>       String s =
(String)p.remove("sun.nio.MaxDirectMemorySize");<br/>       System.setProperties(p);      
if (s != null) {<br/>           if (s.equals("-1")) {               //
-XX:MaxDirectMemorySize not given, take default               directMemory =
Runtime.getRuntime().maxMemory();           } else {               long l =
Long.parseLong(s);               if (l &gt; -1)                   directMemory = l;       
   }       }       return directMemory;<br/>   } 


New Comment: 
There's something else going on though, b/c given the Bits code sample above you can't
allocate a chunk larger than Max at all.  And this works fine w/ default args:<div
class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"><pre
class="code-java">    <span class="code-keyword">public</span> <span
class="code-keyword">static</span> void main(<span class="code-object">String</span>[]
args)    {        ByteBuffer.allocateDirect(90 * 1024 * 1024);        <span
class="code-object">System</span>.out.println(<span class="code-quote">"ok"</span>);   
}</pre></div></div> 


New Comment: 
Interesting, it's exactly 2x the 64M you pasted: default sun.misc.VM.maxDirectMemory()) ==
129957888.So allocating 90MB works fine but 256M fails with OOM. 


New Comment: 
For single allocation thats true.... the following code works!... but wont our byte[]
within a column less than that? is this a real concern?    final int SIZE = 1024;<br/>   
final int KBS = 1024 * 1024;    for (int i = 0; i &lt; KBS; i++) {     
ByteBuffer.allocateDirect(SIZE );      System.out.println("allocating: "+ i);    }   
System.out.println("ok");<br/>    Thread.sleep(10000);<br/>  } 


New Comment: 
Those are never promoted to old gen, though, so the JVM can run the cleanup in the
frequent and cheap new-gen collections.  Once you promote to old gen it gets much messier
(because old gen collections can be days apart and take multiple seconds to finish). 


New Comment: 
Again coming back to the original POC code... where we will reuse the BB's which are not
GC'ed (using weak references) shouldn't that approach work? (if we are not going to use
JNA) i think that way we can guarantee to some extent that we dont fragment the Direct
Memory... Assuming most of our queries results will be approx of the same size (where
chunk size can be defined by the user). 


New Comment: 
I'm still not a fan of writing essentially a poorly-optimized malloc in java, on top of
the native one.Let's hope JNA gets a release out soon. <img class="emoticon"
src="https://issues.apache.org/jira/images/icons/emoticons/smile.png" height="16"
width="16" align="absmiddle" alt="" border="0"/> 


New Comment: 
Could we get a rebase on 1969-rollup-and-config on trunk? 


New Comment: 
Rebased to trunk + a hack/workaround for JNA-179, i have tested this patch and i think
with this change we should commit this patch... the performance looks very good with this
update. 


New Comment: 
what is the hack/workaround? 


New Comment: 
used reflection to change the map into a synchronized WeakHashMap in SerializingCache<div
class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"><pre
class="code-java">    <span class="code-keyword">static</span>     {    	hackJNA();    }  
 /**     * <span class="code-keyword">this</span> is a hack to make the WeakHashMap
thread-safe.      * Bug ID: JNA-179 {@link http:<span
class="code-comment">//java.net/jira/browse/JNA-179}</span>     */    <span
class="code-keyword">private</span> <span class="code-keyword">static</span> void
hackJNA()    {        <span class="code-keyword">try</span>        {            Field h =
Memory.<span class="code-keyword">class.</span>getDeclaredField(<span
class="code-quote">"buffers"</span>);            h.setAccessible(<span
class="code-keyword">true</span>);            Map map = Collections.synchronizedMap(<span
class="code-keyword">new</span> WeakHashMap());            h.set(<span
class="code-keyword">null</span>, map);        }        <span
class="code-keyword">catch</span> (Exception e)        {            <span
class="code-keyword">throw</span> <span class="code-keyword">new</span>
RuntimeException(e);        }    }</pre></div></div> 


New Comment: 
Doesn't that still leaves us with the segfaulting problem from map entries for freed
buffers (the other part of JNA-179)? 


New Comment: 
hmmm... if we avoid using getByteBuffer this issue wont show up right? i think we dont
need ByteBuffer in this ticket (we only need it for #2167)... Agree? if yes then i can
submit changes to this patch (ByteBufferOutputStream to MemoryOS and BBIS to MIS). 


New Comment: 
Yes, using the raw Memory should work.  (You don't need the synchronization hack either,
if you avoid BB entirely.)I've rebased again, fixed some tests, and split it back up into
two patches. At worst, we can commit 01 now and 02 for 0.8.1 or whenever JNA gets a
release out.One other problem: the configuration option (in patch 01) is causing a
problem.<div class="preformatted panel" style="border-width: 1px;"><div
class="preformattedContent panelContent"><pre>ant clean test
-Dtest.name=DatabaseDescriptorTestBuildfile    [junit] Testcase:
testKSMetaDataSerialization(org.apache.cassandra.config.DatabaseDescriptorTest):	Caused an
ERROR    [junit] java.lang.String cannot be cast to org.apache.avro.util.Utf8    [junit]
java.lang.ClassCastException: java.lang.String cannot be cast to org.apache.avro.util.Utf8
   [junit] 	at org.apache.avro.util.Utf8.compareTo(Utf8.java:27)    [junit] 	at
org.apache.avro.generic.GenericData.compare(GenericData.java:523)    [junit] 	at
org.apache.avro.specific.SpecificData.compare(SpecificData.java:190)    [junit] 	at
org.apache.avro.generic.GenericData.compare(GenericData.java:517)    [junit] 	at
org.apache.avro.specific.SpecificData.compare(SpecificData.java:190)    [junit] 	at
org.apache.avro.generic.GenericData.compare(GenericData.java:494)    [junit] 	at
org.apache.avro.specific.SpecificData.compare(SpecificData.java:190)    [junit] 	at
org.apache.avro.generic.GenericData.compare(GenericData.java:508)    [junit] 	at
org.apache.avro.specific.SpecificData.compare(SpecificData.java:190)    [junit] 	at
org.apache.avro.generic.GenericData.compare(GenericData.java:494)    [junit] 	at
org.apache.avro.specific.SpecificData.compare(SpecificData.java:190)    [junit] 	at
org.apache.avro.specific.SpecificRecordBase.compareTo(SpecificRecordBase.java:45)   
[junit] 	at org.apache.avro.specific.SpecificRecordBase.equals(SpecificRecordBase.java:35)
   [junit] 	at
org.apache.cassandra.config.DatabaseDescriptorTest.serDe(DatabaseDescriptorTest.java:42)  
 [junit] 	at
org.apache.cassandra.config.DatabaseDescriptorTest.testKSMetaDataSerialization(DatabaseDescriptorTest.java:66)</pre></div></div> 


New Comment: 
The test failure was due to CFMetaData:335. <br/>Also, 0001-introduce...txt didn't apply
cleanly due to import rebasing.Both those changes are in 1969-0001-v2.txt (where the
correct patch application is 0001-v2, then 0002...). 


New Comment: 
Committed 01 w/ the CFMD fix.New 02 attached w/ isCopying optimization replaced (got lost
in one of the rebases/squashes). 


New Comment: 
Attached patch will do the iteration over the memory directly. I think this can be
committed too... <a href="https://issues.apache.org/jira/browse/CASSANDRA-2167" title="Add
a deserialize(ByteBuffer) method to ColumnFamilySerializer" class="issue-link"
data-issue-key="CASSANDRA-2167"><del>CASSANDRA-2167</del></a> can be used to track the
copy less implementation once JNA bug is fixed.... Agree? 


New Comment: 
can you update w/ the isCopying fixes? 


New Comment: 
Integrated in Cassandra #829 (See <a
href="https://hudson.apache.org/hudson/job/Cassandra/829/" class="external-link"
rel="nofollow">https://hudson.apache.org/hudson/job/Cassandra/829/</a>) 


New Comment: 
What happens if someone asks for SerializingCacheProvider but doesn't have JNA installed? 


New Comment: 
V4 throws RTE when JNA.Memory is not found while initializing the Provider. CQL doesn't
translate the exception well (which should be addressed in a different ticket?). 


New Comment: 
Seeing errors in server tests: looks due to the cache provider...<div class="preformatted
panel" style="border-width: 1px;"><div class="preformattedContent panelContent"><pre>ERROR
[pool-1-thread-1] 2011-04-06 10:12:28,133 Cassandra.java (line 4604) Internal error
processing system_update_column_familyjava.lang.NullPointerException        at
org.apache.cassandra.config.CFMetaData.apply(CFMetaData.java:641)        at
org.apache.cassandra.db.migration.UpdateColumnFamily.&lt;init&gt;(UpdateColumnFamily.java:59)
       at
org.apache.cassandra.thrift.CassandraServer.system_update_column_family(CassandraServer.java:898)
       at
org.apache.cassandra.thrift.Cassandra$Processor$system_update_column_family.process(Cassandra.java:4598)
       at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:3285)    
   at
org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:187)
       at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)       
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)       
at java.lang.Thread.run(Thread.java:680)</pre></div></div> 


New Comment: 
fixed in r1089522 


New Comment: 
Committed v4, with some changes to allow the ConfigurationException in
FBU.newCacheProvider to propagate to the client (both old-school and CQL). 


