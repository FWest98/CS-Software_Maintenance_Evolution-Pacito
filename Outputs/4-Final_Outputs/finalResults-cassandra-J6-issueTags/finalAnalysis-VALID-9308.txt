Pattern changes caused by commit: 95cf9a5f0d5c437a9e042018eadc698e3fd5f9e0

From: Strategy-1
To:   Strategy-0


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-9308.txt 

commit 95cf9a5f0d5c437a9e042018eadc698e3fd5f9e0
Author: Jonathan Ellis <jbellis@apache.org>

    fix 2i updates with indentical values and timestamps
    patch by Sam Tunnicliffe; reviewed by jbellis for CASSANDRA-5540



==================================
 Issue CASSANDRA-5540 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-5540] Concurrent secondary index updates remove rows from the index
-----------------

-----------------
Summary: Concurrent secondary index updates remove rows from the index
-----------------

-----------------
Issue type: Bug
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Mon, 6 May 2013 11:04:16 +0000
-----------------

-----------------
Resolved at: Thu, 9 May 2013 22:42:02 +0000
-----------------

-----------------
Assigned to: Sam Tunnicliffe
-----------------

-----------------
Description: 

Existing rows disappear from secondary index when doing simultaneous updates of a row
with the same secondary index value.

Here is a little pycassa script that reproduces a
bug. The script inserts 4 rows with same secondary index value, reads those rows back and
check that there are 4 of them.<br/>Please run two instances of the script simultaneously
in two separate terminals in order to simulate concurrent updates:
<div class="code panel"
style="border-width: 1px;"><div class="codeContent panelContent"><pre
class="code-java">-----scrpit.py START-----<span class="code-keyword">import</span>
pycassafrom pycassa.index <span class="code-keyword">import</span> *pool =
pycassa.ConnectionPool(<span class="code-quote">'ks123'</span>)cf =
pycassa.ColumnFamily(pool, <span class="code-quote">'cf1'</span>)<span
class="code-keyword">while</span> True:    <span class="code-keyword">for</span> rowKey in
xrange(4):        cf.insert(str(rowKey), {<span class="code-quote">'indexedColumn'</span>:
<span class="code-quote">'indexedValue'</span>})    index_expression =
create_index_expression(<span class="code-quote">'indexedColumn'</span>, <span
class="code-quote">'indexedValue'</span>)    index_clause =
create_index_clause([index_expression])    rows = cf.get_indexed_slices(index_clause)   
length = len(list(rows))    <span class="code-keyword">if</span> length == 4:        pass 
  <span class="code-keyword">else</span>:        print <span class="code-quote">'found
just %d rows out of 4'</span> % lengthpool.dispose()---script.py FINISH------schema cli
start---create keyspace ks123  with placement_strategy = <span
class="code-quote">'NetworkTopologyStrategy'</span>  and strategy_options = {datacenter1 :
1}  and durable_writes = <span class="code-keyword">true</span>;use ks123;create column
family cf1  with column_type = <span class="code-quote">'Standard'</span>  and comparator
= <span class="code-quote">'AsciiType'</span>  and default_validation_class = <span
class="code-quote">'AsciiType'</span>  and key_validation_class = <span
class="code-quote">'AsciiType'</span>  and read_repair_chance = 0.1  and
dclocal_read_repair_chance = 0.0  and populate_io_cache_on_flush = <span
class="code-keyword">false</span>  and gc_grace = 864000  and min_compaction_threshold = 4
 and max_compaction_threshold = 32  and replicate_on_write = <span
class="code-keyword">true</span>  and compaction_strategy = <span
class="code-quote">'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'</span>
 and caching = <span class="code-quote">'KEYS_ONLY'</span>  and column_metadata = [   
{column_name : <span class="code-quote">'indexedColumn'</span>,    validation_class :
AsciiType,    index_name : <span class="code-quote">'INDEX1'</span>,    index_type : 0}] 
and compression_options = {<span class="code-quote">'sstable_compression'</span> : <span
class="code-quote">'org.apache.cassandra.io.compress.SnappyCompressor'</span>};---schema
cli finish---</pre></div></div>
Test cluster created with 'ccm create --cassandra-version
1.2.4 --nodes 1 --start testUpdate'
 

-----------------

-----------------
Comments: 

New Comment: 
Hmm.  It looks like this can happen when multiple inserts happen at the same timestamp,
since we delete the existing entry with its own timestamp.  But if the replacement has the
same timestamp, then the tombstone wins the tie.Any clever ideas to fix this <a
href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=beobal"
class="user-hover" rel="beobal">beobal</a>? 


New Comment: 
I don't think this is caused by the index updates in KeysSearcher. There, we only compare
the values &amp; since this test always writes the same values the index entry is never
deemed stale, and so we don't ever write a tombstone. The test script does reproduce the
issue completely reliably though, so I'll dig in and find the actual cause. 


New Comment: 
Sorry <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbellis"
class="user-hover" rel="jbellis">Jonathan Ellis</a> I misunderstood, I see what you mean
now. No clever ideas yet, but I'm working on it. 


New Comment: 
Can we just special-case StandardUpdater.update to check for oldColumn.equals(column) and
no-op that?(NB I think the compaction code that calls <tt>remove</tt> would need to check
for <tt>.equals</tt> instead of <tt>==</tt> as well.) 


New Comment: 
Can we just remove the deletion from StandardUpdater.update() altogether? That seems to be
fine for realtime updates (I no longer see the missing rows &amp; all unit tests are
passing) but will it screw with compaction? 


New Comment: 
Right, the reason that's there is that compaction can't know to purge the stale index
entries for values that never made it into an sstable. 


New Comment: 
Checking oldColumn.equals(column) in SU.update() isn't sufficient. I found that even with
the short circuit, occasionally the test script would return only 3 of the 4 expected
columns. My suspicion is that this is caused by the delete &amp; subsequent insert in
SU.update() being non-atomic, though I haven't proved this. Rather than go down that
rabbit hole, I've split the Updater implementation into 2 subclasses - LiveUpdater &amp;
CompactionUpdater. The difference between them is that the CU behaves like SU and always
purges old values, whereas LU just upserts into the index. SIM.updaterFor() now takes a
second argument to determine whether the updater is for processing live updates or for use
during compaction.Unit tests pass &amp; the test script runs without issue. 


New Comment: 
How does this avoid leaking index entries that will never be cleaned up by compaction? 


New Comment: 
yes, you're right that's dumb sorry. It took me a while, but there's actually 2 issues
here. The first, as you identified, is caused by overwrites with identical timestamps and
is fixed by making the case where oldColumn.equals(newColumn) a no-op. The second is the
window of inconsistency that I mentioned earlier. When the 2 instances of the test script
are running, its possible for one to query the index while inbetween the old index entry
being deleted &amp; the new one inserted, leading to a "missing" result. To address that,
I've reversed the order so that the new entry is added before the old one is removed. This
should be safe for readers due to the checking for stale values in the index searcher. 


New Comment: 
LGTM; committed. 


New Comment: 
Fabulous! Thank you very much for the fix! 


New Comment: 
Is it a correct assessment that this issues "affects" begins with the initial
implementation of 2i in 0.7? If not, when? 


New Comment: 
No, affects 1.2.0+ as indicated. 


