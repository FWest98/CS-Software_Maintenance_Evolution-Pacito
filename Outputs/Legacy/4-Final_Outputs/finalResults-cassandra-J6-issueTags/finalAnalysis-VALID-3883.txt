Pattern changes caused by commit: 1b24a02c4cf8d4fce042e3f9b2f34945b729fcef

From: Abstract Factory-3
To:   Abstract Factory-2

From: Factory Method-3
To:   Factory Method-2

From: Mediator-2
To:   Mediator-1


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-3883.txt 

commit 1b24a02c4cf8d4fce042e3f9b2f34945b729fcef
Author: Jonathan Ellis <jbellis@apache.org>

    force GC to reclaim disk space on flush, if necessary
    patch by jbellis; reviewed by slebresne for CASSANDRA-2404



==================================
 Issue CASSANDRA-2404 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-2404] if out of disk space reclaim compacted SSTables during memtable flush
-----------------

-----------------
Summary: if out of disk space reclaim compacted SSTables during memtable flush
-----------------

-----------------
Issue type: Improvement
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Wed, 30 Mar 2011 10:33:37 +0000
-----------------

-----------------
Resolved at: Mon, 25 Apr 2011 17:04:51 +0000
-----------------

-----------------
Assigned to: Jonathan Ellis
-----------------

-----------------
Description: 

During compaction if there is not enough disk space we invoke GC to reclaim unused
space.

During memtable and binary memtable flush we just error out if there is not enough
disk space to flush the table. 

Can we make cfs.createFlushWriter() use the same logic as
Table.getDataFileLocation() to reclaim space if needed?
 

-----------------

-----------------
Comments: 

New Comment: 
Actually, I would be all for <em>moving</em> the logic from getDataFileLocation to
createFlushWriter... not having room to flush is much more urgent than not having room to
compact, and as a node gets closer to full, large bucket compactions will begin to spam GC
for compactions that aren't going to be possible anyway. 


New Comment: 
The reason we didn't do this historically is we didn't know how much free space should be
the Panic Threshold on flush, whereas compaction has an easy-to-compute upper bound. Now
we we can compute the flush size very easily (basically the throughput value + 2xkey
sizes) so we can run the same "if not enough room then attempt a GC" logic. 


New Comment: 
Patch to route getFlushPath through table.getDataFileLocation so it shares the
gc-to-clean-up-if-necessary logic. 


New Comment: 
Minor comments: in the estimation, the index size could be slightly improved by adding 10
* nb of keys (2 for the written size of the key + 8 for the recorded position). It's  an
estimation though so not a huge deal.But otherwise, +1.Made me wonder (but not directly
related to the ticket), wouldn't it be "safer" when we're out of space to hold on the
memtable (and thus block writes fairly quickly) instead of dropping the memtable "fairly
silently" (we throw a RuntimeException that will be logged, but it still could be some
time during which the node seems to accept write fine but will throw them out). 


New Comment: 
committed.<blockquote>the index size could be slightly improved by adding 10 * nb of keys
(2 for the written size of the key + 8 for the recorded position).</blockquote>Right. And
we could add in similar numbers for the data component (key size, row size, number of
columns int, ...) but these are going to be small compared to the bloom filter component,
as well as column BF + index for wide rows. So it feels like pretending to be more
accurate than it really is to go after details like that.<blockquote>wouldn't it be
"safer" when we're out of space to hold on the memtable (and thus block writes fairly
quickly) instead of dropping the memtable "fairly silently" (we throw a RuntimeException
that will be logged, but it still could be some time during which the node seems to accept
write fine but will throw them out).</blockquote>As long as we don't mark the commitlog as
flushed, I'd rather accept that status quo than block writes during each flush (which IS
noticable as we discovered in <a
href="https://issues.apache.org/jira/browse/CASSANDRA-2333" title="Clean up thread pool
and queue sizes" class="issue-link"
data-issue-key="CASSANDRA-2333"><del>CASSANDRA-2333</del></a>). 


