Pattern changes caused by commit: d401d9f1deaad08ff0a76e3795ec4b1c0fa72421

From: Decorator-2
To:   Decorator-1

From: Facade-0
To:   Facade-1

From: Flyweight-2
To:   Flyweight-1

From: Mediator-3
To:   Mediator-1

From: Strategy-0
To:   Strategy-1


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-7781.txt 

commit d401d9f1deaad08ff0a76e3795ec4b1c0fa72421
Author: Yuki Morishita <yukim@apache.org>

    Fix duplicate SSTable reference when stream session failed; patch by yukim reviewed by Sylvain Lebresne for CASSANDRA-3306



==================================
 Issue CASSANDRA-3306 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-3306] Failed streaming may cause duplicate SSTable reference
-----------------

-----------------
Summary: Failed streaming may cause duplicate SSTable reference
-----------------

-----------------
Issue type: Bug
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Tue, 4 Oct 2011 14:39:28 +0000
-----------------

-----------------
Resolved at: Wed, 31 Oct 2012 16:13:45 +0000
-----------------

-----------------
Assigned to: Yuki Morishita
-----------------

-----------------
Description: 

during stress testing, i always get this error making leveledcompaction strategy
unusable. Should be easy to reproduce - just write fast.

ERROR <span
class="error">&#91;CompactionExecutor:6&#93;</span> 2011-10-04 15:48:52,179
AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread<span
class="error">&#91;CompactionExecutor:6,5,main&#93;</span><br/>java.lang.AssertionError<br/>	at
org.apache.cassandra.db.DataTracker$View.newSSTables(DataTracker.java:580)<br/>	at
org.apache.cassandra.db.DataTracker$View.replace(DataTracker.java:546)<br/>	at
org.apache.cassandra.db.DataTracker.replace(DataTracker.java:268)<br/>	at
org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:232)<br/>	at
org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:960)<br/>	at
org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:199)<br/>	at
org.apache.cassandra.db.compaction.LeveledCompactionTask.execute(LeveledCompactionTask.java:47)<br/>	at
org.apache.cassandra.db.compaction.CompactionManager$1.call(CompactionManager.java:131)<br/>	at
org.apache.cassandra.db.compaction.CompactionManager$1.call(CompactionManager.java:114)<br/>	at
java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)<br/>	at
java.util.concurrent.FutureTask.run(FutureTask.java:138)<br/>	at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)<br/>	at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)<br/>	at
java.lang.Thread.run(Thread.java:662)

and this is in json data for table:

{<br/> 
"generations" : [ 
{    "generation" : 0,    "members" : [ 459, 460, 461, 462, 463, 464,
465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482,
483, 484 ]  }
, 
{    "generation" : 1,    "members" : [ ]  }
, 
{    "generation" : 2,   
"members" : [ ]  }
, 
{    "generation" : 3,    "members" : [ ]  }
, 
{    "generation" :
4,    "members" : [ ]  }
, 
{    "generation" : 5,    "members" : [ ]  }
, 
{   
"generation" : 6,    "members" : [ ]  }
, 
{    "generation" : 7,    "members" : [ ]  }

]<br/>}
 

-----------------

-----------------
Comments: 

New Comment: 
another problem. why not store data in some system CF? would be probably safer
choice.ERROR <span class="error">&#91;CompactionExecutor:5&#93;</span> 2011-10-04
17:13:13,922 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread<span
class="error">&#91;CompactionExecutor:5,5,main&#93;</span><br/>java.io.IOError:
java.io.IOException: Failed to rename \var\lib\cassandra\data\test\sipdb.json to
\var\lib\cassandra\data\test\sipdb-old.json<br/>	at
org.apache.cassandra.db.compaction.LeveledManifest.serialize(LeveledManifest.java:382)<br/>	at
org.apache.cassandra.db.compaction.LeveledManifest.promote(LeveledManifest.java:182)<br/>	at
org.apache.cassandra.db.compaction.LeveledCompactionStrategy.handleNotification(LeveledCompactionStrategy.java:152)<br/>	at
org.apache.cassandra.db.DataTracker.notifySSTablesChanged(DataTracker.java:466)<br/>	at
org.apache.cassandra.db.DataTracker.replace(DataTracker.java:275)<br/>	at
org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:232)<br/>	at
org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:960)<br/>	at
org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:199)<br/>	at
org.apache.cassandra.db.compaction.LeveledCompactionTask.execute(LeveledCompactionTask.java:47)<br/>	at
org.apache.cassandra.db.compaction.CompactionManager$1.call(CompactionManager.java:131)<br/>	at
org.apache.cassandra.db.compaction.CompactionManager$1.call(CompactionManager.java:114)<br/>	at
java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)<br/>	at
java.util.concurrent.FutureTask.run(FutureTask.java:138)<br/>	at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)<br/>	at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)<br/>	at
java.lang.Thread.run(Thread.java:662)<br/>Caused by: java.io.IOException: Failed to rename
\var\lib\cassandra\data\test\sipdb.json to
\var\lib\cassandra\data\test\sipdb-old.json<br/>	at
org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:64)<br/>	at
org.apache.cassandra.db.compaction.LeveledManifest.serialize(LeveledManifest.java:375)<br/>	...
15 more 


New Comment: 
Because then you get into hairy cyclical situations where you can't read the manifest
until you replay the commitlog, but replaying the commitlog requires writing new sstables
and thus knowing the manifest 


New Comment: 
as i understand new flushed tables are placed at level 0. Just replay commitlog and put
all new stuff in lvl 0. after comitlog is done, it can do voodoo shuffles.but why not to
rename tables like table-h-333-l1-Data.db?idea to have stables with non overlapping key
ranges is interesting, but read performance is kinda slow (about 50% of normal) here. Its
cassandra core modified to get advantage of leveled tables? i.e. search one sstable at
level1, one at lvl2 using bloom filters for key? 


New Comment: 
This isn't really a great place to rehash <a
href="http://leveldb.googlecode.com/svn/trunk/doc/impl.html" class="external-link"
rel="nofollow">http://leveldb.googlecode.com/svn/trunk/doc/impl.html</a> and <a
href="https://issues.apache.org/jira/browse/CASSANDRA-1608" title="Redesigned Compaction"
class="issue-link" data-issue-key="CASSANDRA-1608"><del>CASSANDRA-1608</del></a>. 


New Comment: 
<blockquote>why not store data in some system CF? would be probably safer
choice.</blockquote>This has historically been a bad idea, see <a
href="https://issues.apache.org/jira/browse/CASSANDRA-1155" title="keep persistent row
statistics" class="issue-link"
data-issue-key="CASSANDRA-1155"><del>CASSANDRA-1155</del></a>, then <a
href="https://issues.apache.org/jira/browse/CASSANDRA-1318" title="CommitLogTest and
RecoveryManager2Test is failing in trunk" class="issue-link"
data-issue-key="CASSANDRA-1318"><del>CASSANDRA-1318</del></a> and finally <a
href="https://issues.apache.org/jira/browse/CASSANDRA-1430" title="SSTable statistics
causing intermittent CL test failures in trunk." class="issue-link"
data-issue-key="CASSANDRA-1430"><del>CASSANDRA-1430</del></a>. 


New Comment: 
I don't suppose you were using column family truncation in your tests, where you? 


New Comment: 
no truncation, no supercolumns. 


New Comment: 
Are you still able to reproduce reliably? Because we aren't and being able to would help
considerably, so if you are and could share whatever script you're using to reproduce,
that would be awesome. 


New Comment: 
i tested it on 1.0 final and it worked without error for 1 test run. i will give it
another test without index. 


New Comment: 
I'll note that Ramesh Natarajan reported on the mailing list what clearly appears to be
the same bug (<a
href="http://www.mail-archive.com/user@cassandra.apache.org/msg18146.html"
class="external-link"
rel="nofollow">http://www.mail-archive.com/user@cassandra.apache.org/msg18146.html</a>),
but while not using leveled compaction. I also think he was using the 1.0.0 final. 


New Comment: 
I'll note that more info have been added to the messages thrown by the exception here in
1.0.1. So if someone can reproduce this issue on 1.0.1, it would be useful to get the
stacktrace (the full system.log would actually be even better). 


New Comment: 
Thisã€€AssertionError happened always in cassandra1.0.0 ,not just only in
LeveledCompactionStrategy 


New Comment: 
I suppose it's a bug in DataTracker . 


New Comment: 
As I already said, if you are able to reproduce this, please try reproducing with 1.0.3.
And if you are still able to, please attach you system.log with the exception here because
it will have more info on the error that should help. And if you're not able to reproduce
with 1.0.3, then I guess it means we've fixed it without knowing. 


New Comment: 
Running under 1.0.4, can easily reproduce this by just kicking of a repair of any
LeveledCompactionStrategy CF.  The 'zero' on the assert indicates the value (added that to
the code to see what the value was): java.lang.AssertionError: 0<br/>        at
org.apache.cassandra.db.compaction.LeveledManifest.promote(LeveledManifest.java:178)<br/> 
      at
org.apache.cassandra.db.compaction.LeveledCompactionStrategy.handleNotification(LeveledCompactionStrategy.java:141)<br/>
       at
org.apache.cassandra.db.DataTracker.notifySSTablesChanged(DataTracker.java:481)<br/>      
 at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:275)<br/>        at
org.apache.cassandra.db.DataTracker.addSSTables(DataTracker.java:237)<br/>        at
org.apache.cassandra.db.DataTracker.addStreamedSSTable(DataTracker.java:242)<br/>       
at org.apache.cassandra.db.ColumnFamilyStore.addSSTable(ColumnFamilyStore.java:920)<br/>  
     at
org.apache.cassandra.streaming.StreamInSession.closeIfFinished(StreamInSession.java:141)<br/>
       at
org.apache.cassandra.streaming.IncomingStreamReader.read(IncomingStreamReader.java:103)<br/>
       at
org.apache.cassandra.net.IncomingTcpConnection.stream(IncomingTcpConnection.java:184)<br/>
       at
org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:81)Relevant
lines from system.log leading up the it:  INFO <span
class="error">&#91;FlushWriter:794&#93;</span> 2011-12-01 14:23:22,966 Memtable.java (line
275) Completed flushing /var/lib/cassandra/data/sso/Sessions-hc-12524-Data.db (1119784
bytes)<br/> INFO <span class="error">&#91;CompactionExecutor:2379&#93;</span> 2011-12-01
14:23:22,969 CompactionTask.java (line 112) Compacting <span
class="error">&#91;SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12501-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12517-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12513-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12512-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12502-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12507-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12519-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12500-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12508-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12504-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12510-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12515-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12509-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12524-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12514-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12518-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12505-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12516-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12511-Data.db&#39;),
SSTableReader(path=&#39;/var/lib/cassandra/data/sso/Sessions-hc-12506-Data.db&#39;)&#93;</span><br/>
INFO <span class="error">&#91;AntiEntropyStage:1&#93;</span> 2011-12-01 14:25:06,321
AntiEntropyService.java (line 186) <a href="#ea080b70-1c51-11e1-0000-692e0c239dfd">repair
#ea080b70-1c51-11e1-0000-692e0c239dfd</a> Received merkle tree for Sessions from
/xxxxxxxx<br/>ERROR <span class="error">&#91;Thread-177&#93;</span> 2011-12-01
14:25:17,863 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread<span
class="error">&#91;Thread-177,5,main&#93;</span><br/>java.lang.AssertionError: 0  <span
class="error">&#91;see above&#93;</span>If you want more let me know I can reproduce
instantly. 


New Comment: 
Joe, your assertion is the one in <a
href="https://issues.apache.org/jira/browse/CASSANDRA-3536" title="Assertion error during
bootstraping cassandra" class="issue-link"
data-issue-key="CASSANDRA-3536"><del>CASSANDRA-3536</del></a> (where I've attached a patch
fixing it).  Closing this other one as cantrepro. 


New Comment: 
This error actually happens on 1.1. And I can easily reproduce with unit test(Test code
attached).<div class="code panel" style="border-width: 1px;"><div class="codeContent
panelContent"><pre class="code-java">    [junit] ERROR 17:34:46,696 Fatal exception in
thread <span class="code-object">Thread</span>[CompactionExecutor:3,1,main]    [junit]
java.lang.AssertionError: Expecting <span class="code-keyword">new</span> size of 2, got 1
<span class="code-keyword">while</span> replacing [SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-1-Data.db'</span>),
SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-5-Data.db'</span>),
SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-4-Data.db'</span>),
SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-2-Data.db'</span>)]
by [SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-6-Data.db'</span>)]
in View(pending_count=0, sstables=[SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-1-Data.db'</span>),
SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-2-Data.db'</span>),
SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-4-Data.db'</span>),
SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-4-Data.db'</span>),
SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-5-Data.db'</span>)],
compacting=[SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-1-Data.db'</span>),
SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-5-Data.db'</span>),
SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-4-Data.db'</span>),
SSTableReader(path=<span
class="code-quote">'build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-2-Data.db'</span>)])
   [junit] 	at org.apache.cassandra.db.DataTracker$View.newSSTables(DataTracker.java:651) 
  [junit] 	at org.apache.cassandra.db.DataTracker$View.replace(DataTracker.java:616)   
[junit] 	at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:320)    [junit]
	at org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:253)   
[junit] 	at
org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:994)
   [junit] 	at
org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:200)   
[junit] 	at
org.apache.cassandra.db.compaction.CompactionManager$1.runMayThrow(CompactionManager.java:154)
   [junit] 	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)   
[junit] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)   
[junit] 	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)    [junit]
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)    [junit] 	at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)   
[junit] 	at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)    [junit]
	at java.lang.<span class="code-object">Thread</span>.run(<span
class="code-object">Thread</span>.java:680)</pre></div></div>The cause is actually in
streaming. StreamInSession can add duplicate reference to SSTable to DataTracker when it
is left even after stream session finishes. This typically happens when source node is
marked as dead by FailureDetector during streaming session(GC storm is the one I saw) and
keep sending file in same session after the node comes back. 


New Comment: 
Test code attached. Compaction strategy is not related. 


New Comment: 
Good analysis Yuki. I'm not really sure what is the right fix though. Given that this
should very rarely happen (repair uses a much higher failure detection threshold than the
normal one, though maybe we can increase it even more to make this even less likely) and
that I don't seen any obvious way to avoid that kind of situation, maybe making
DataTracker handle duplicate addition of a SSTableReader is the simplest thing to do. The
obvious way to do that would be to change the View sstables List to a Set, which leads me
to the current commentary in the code:<div class="preformatted panel" style="border-width:
1px;"><div class="preformattedContent panelContent"><pre>        // We can't use a
SortedSet here because "the ordering maintained by a sorted set (whether or not an       
// explicit comparator is provided) must be &lt;i&gt;consistent with equals&lt;/i&gt;." 
In particular,        // ImmutableSortedSet will ignore any objects that compare equally
with an existing Set member.        // Obviously, dropping sstables whose max column
timestamp happens to be equal to another's        // is not acceptable for us.  So, we use
a List instead.</pre></div></div>I think that comment is obsolete. Namely, it was added
with <a href="https://issues.apache.org/jira/browse/CASSANDRA-2498" title="Improve read
performance in update-intensive workload" class="issue-link"
data-issue-key="CASSANDRA-2498"><del>CASSANDRA-2498</del></a> and at the time the list of
sstable was kept in max timestamp order at all time. But since then, we've moved the
sorting in max timestamp in CollationController directly (which is less fragile), so the
order inside DataTracker doesn't matter anymore. 


New Comment: 
<blockquote>This typically happens when source node is marked as dead by FailureDetector
during streaming session(GC storm is the one I saw) and keep sending file in same session
after the node comes back</blockquote>But we close the session on convict, so shouldn't it
start a new one? 


New Comment: 
<blockquote>But we close the session on convict, so shouldn't it start a new
one?</blockquote>Yes, StreamInSession gets closed and removed on convict <em>once</em>.
But if GC pause happens in the middle of streaming session, the node resumes streaming in
the same session after GC. Since resumed stream carries session ID that is once closed on
receiver side, StreamInSession is created again with the same old session ID and this time
just 1 file to receive.<br/>This continues again and again until source node's
StreamingOutSession sends all files.<br/>You can see this in receiver's log file like
below:<div class="code panel" style="border-width: 1px;"><div class="codeContent
panelContent"><pre class="code-java">INFO [<span class="code-object">Thread</span>-50]
2012-10-20 13:13:26,574 StreamInSession.java (line 214) Finished streaming session 10 from
/10.xx.xx.xxINFO [<span class="code-object">Thread</span>-51] 2012-10-20 13:13:29,691
StreamInSession.java (line 214) Finished streaming session 10 from /10.xx.xx.xxINFO [<span
class="code-object">Thread</span>-52] 2012-10-20 13:13:32,957 StreamInSession.java (line
214) Finished streaming session 10 from /10.xx.xx.xx</pre></div></div>Duplication happens
during this partially broken streaming session. Because StreamInSession is removed after
sending SESSION_FINISHED reply, and StreamOutSession keeps sending files, sometimes the
same StreamInSession instance receives more than 1 file and calls closeIfFinished every
time it received the file.<br/>(Sorry, this is hard to explain in words.<br/><a
href="https://github.com/apache/cassandra/blob/cassandra-1.1.6/src/java/org/apache/cassandra/streaming/StreamInSession.java#L181"
class="external-link"
rel="nofollow">https://github.com/apache/cassandra/blob/cassandra-1.1.6/src/java/org/apache/cassandra/streaming/StreamInSession.java#L181</a>
this part is executed multiple times with <em>readers</em> growing by received new
file.)So as Sylvain stated above, changing DataTracker.View's sstable to Set is one way to
eliminate duplicate reference and we should do it. In addition, I'm thinking not to create
duplicate StreamInSession by checking StreamHeader.pendingFiles because this field is only
filled when initiating streaming. 


New Comment: 
That code is a mess so let me give a shot at describing what happens for the record. Say
node1 wants to stream files A, B and C to node2. If everything goes well what happens
is:<ol>	<li>node1 sends the first file A with a StreamHeader that says that A, B and C are
pending files and A is the currently sent file. On node2, a new StreamInSession is created
with those information.</li>	<li>Once A is finished, node2 remove A from the pending file
in the StreamInSession send an acknowledgement to node1, and then node1 sends B with a
StreamHeader with no pending files (basically the list of pending files is only sent the
first time so that the StreamInSession on node2 knows when everything is finished) and B
as current file. When node2 received that StreamHeader, it retrieve the StreamInSession,
setting B as the current files.</li>	<li>Once B is finished, node2 removes it from pending
files, acks to node1 and node1 sends C with a StreamHeader with no pending file and C as
current file.  Node2 retrieven the StreamInSession and modify it accordingly.</li>	<li>At
last, once C is finished, node2 removes it from the pending files. Then it realizes the
pending files are empty and so that the streaming is finished and at that point it adds
all the SSTableReader created so far to the cfs (and acks to node1 the end of the
streaming).</li></ol>Now, the problem is if say node1 is marked dead by mistake by node2
during say the streaming of A. I that happens, the only thing we do on node2 is to close
the session and remove the streamInSession from the global sessions map.  However we don't
shutdown the stream or anything, so if node1 is in fact still alive, what will happen
is:<ol>	<li>A will finish his transfer correctly. Once that's done, node2 will still send
an acknowledgement (probably the first mistake, we could check that the session has been
closed and send an error instead).</li>	<li>Node1 getting it's acknowledgement will send B
with a StreamHeader that has B as current file and no pending files as usual. On
reception, node2 will not find any StreamInSession (it has been removed during the close),
and so it will create a new one as if that was the beginning of a transfer. And that
session will have no pending file (second mistake: if we have to create a new
StreamInSession but there is no pending file at all something wrong has
happened).</li>	<li>Once B is fully streamed, node2 will acknowledge it to node1 and
remove it from it's streamInSession. But that session the new one we just created with no
pending file. So the streamInSession will consider the streaming is finished, and it will
thus add the SSTableReader for B to the cfs.</li>	<li>Because B has been acknowledged,
node1 will start sending C (again, with no pending file in the StreamHeader). This will be
done as soon as B was finished, and so concurrently with the streamInSession on node2
closing itself.</li>	<li>So when node2 receives the StreamHeader with C, it will try to
retrieve the session and will find the previous session. And will happily add C as the
current file for that session (third and fourth mistake: StreamInSession should not add a
file as current unless it is a pending file for this session, and a session could detect
that it's being reused even though it has just detected itself as finished).</li>	<li>Now
when C transfer finishes, the seesion will be notify and since it still has no pending
files, it will once again consider the streaming as complete.  But since it's still the
same session, it still has the SSTableReader for B in its list of created reader (as well
as the one for C now). And that's when it adds B for a second time to the
DataTracker.</li></ol>I also not that we end up without having ever add the SSTableReader
for A to the cfs since the very first StreamInSession was never finished. This is not a
big deal in that the stream itself has been indicated as failed to the client anyway, but
just to say that it's not just a problem of duplicating a SSTableReader preference.Anyway,
let me back on what I said earlier. We should definitively fix some if not all of the
"mistake" above (and send a SESSION_FAILURE to node1 as soon as we detect something is
wrong).But that being said, my comment on the comment in DataTracker being obsolete still
stand, and replacing the list by a set in there would have at least the advantage of
slightly simplifying the code of DataTracker.View.newSSTables(), as well as being more
resilient if a SSTableReader is added twice. Not a big deal though. 


New Comment: 
Attaching first attempt.<br/>I changed DataTracker.View's sstables to Set, and made stream
fail when file arrives after StreamInSession failed.Changing List to Set for sstables
sometimes makes CollationControllerTest fail. It was introduced in <a
href="https://issues.apache.org/jira/browse/CASSANDRA-4116" title="check most recent TS
values in SSTables when a row tombstone has already been encountered" class="issue-link"
data-issue-key="CASSANDRA-4116"><del>CASSANDRA-4116</del></a>, and I think the test and
CollationController#collectAllData expect sstables to be ordered by timestamp. I'm not
sure if the test is obsolete or we really need sstables to be sorted all the
time.<br/>0002 patch alone will fix the issue, so we can apply that for now. 


New Comment: 
For patch 0002, we shouldn't check the FailureDetector otherwise we don't really fix the
issue. The only way we know this bug can happen is wher the FailureDetector <b>had</b>
marked a node down while it shouldn't have (besides, we just got something from a node so
it's fair to assume it is alive).<blockquote>and I think the test and
CollationController#collectAllData expect sstables to be ordered by
timestamp</blockquote>It doesn't seem to me that collectAllData needs sstable ordered. In
fact, I think that it does a second pass over the sstables iterators just because it
doesn't assume sstables are ordered by max timestamp. Moreover, I'm pretty sure it would
be a bug to assume that. If you look at DataTracker.View.newSSTables, it ends by
<tt>Iterables.addAll(newSSTables, replacements)</tt> which clearly won't maintain any
specific ordering of sstables.<blockquote>I'm not sure if the test is
obsolete.</blockquote>I don't think the test is obsolete but I think we have a minor bug
in CollationController. The test want to test that we correctly exclude sstable whose
maxTimestamp is less than the most recent row tombstone we have. But that test checks
controller.getSstablesIterated(), and for collectAllData, it will count every sstable it
include in the first iteration of collectAllData but don't remove those that are remove by
the second pass. In other words, I think the correct fix is to decrement stablesIterated
in CollationController when in the second pass we remove a sstable (or more simply to set
it to iterators.size() just before we collate everything). 


New Comment: 
<blockquote>we shouldn't check the FailureDetector otherwise we don't really fix the
issue.</blockquote>Ok. I've fixed this and reattached 0002.<blockquote>The test want to
test that we correctly exclude sstable whose maxTimestamp is less than the most recent row
tombstone we have.</blockquote>Right. But I think the test assumes that SSTables are added
to List in order of flush, and that's true as long as we use List. So what I suggest is to
remove that part from the test since we no longer use List.<br/>And sstablesIterated
counter in collectAllData is doing fine because we actually read the data from sstable
when we go over<div class="code panel" style="border-width: 1px;"><div class="codeContent
panelContent"><pre class="code-java">IColumnIterator iter =
filter.getSSTableColumnIterator(sstable);</pre></div></div>before incrementing counter.So
I removed that test from CollationControllerTest in
0001-change-DataTracker.View-s-sstables-from-List-to-Set.patch. 


New Comment: 
<blockquote>Ok. I've fixed this and reattached 0002.</blockquote>Alright, +1 on 0002.
Let's commit that for now to 1.1/1.2 as this fix this ticket.<blockquote>the test assumes
that SSTables are added to List in order of flush<br/>And sstablesIterated counter in
collectAllData is doing fine because we actually read the data</blockquote>Right. I guess
what I meant is that what is tested right now is not really sensible. Relying on the order
of flush is only valid for a small, controlled test, but in reality as soon as compaction
kicks in, the order of sstable in DataTracker will be meaningless even with a List instead
of a Set. Basically the guarantee collectAll gives us today is that it will eliminate
sstables whose maxTimestamp &lt; mostRecentTombstone with just having read the sstable row
header, not the full data. But that's not what sstablesIterated counts so it's broken.That
being said, I think we can improve collectAll in the way described in <a
href="https://issues.apache.org/jira/browse/CASSANDRA-4883" title="Optimize
mostRecentTomstone vs maxTimestamp check in CollationController.collectAllData"
class="issue-link" data-issue-key="CASSANDRA-4883"><del>CASSANDRA-4883</del></a>. If we do
so, the test will pass again without relying on any assumption of the order of sstables in
DataTracker. So overall I suggest moving all of this to <a
href="https://issues.apache.org/jira/browse/CASSANDRA-4883" title="Optimize
mostRecentTomstone vs maxTimestamp check in CollationController.collectAllData"
class="issue-link" data-issue-key="CASSANDRA-4883"><del>CASSANDRA-4883</del></a>. 


New Comment: 
Committed 0002 to 1.1 and trunk. 


New Comment: 
I understand that this has been fixed in newer versions of Cassandra.But I'm currently
seeing this exact issue on a production 1.1.1 node in my cluster.What should be my next
step?Do I simply restart it?Run cleanup? Scrub? Repair?Sounds like repair would just fail
with the same problem.Any advice would be appreciated. 


New Comment: 
Yes, restarting the node will help.<br/>No need to clean up/scrub.Please use
user@cassandra.apache.org mailing list for these type of questions. 


