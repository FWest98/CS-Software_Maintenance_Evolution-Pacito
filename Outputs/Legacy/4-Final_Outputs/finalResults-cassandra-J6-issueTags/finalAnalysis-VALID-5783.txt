Pattern changes caused by commit: a95eafdccd398e775646688e9e37e0ae29e1114a

From: Facade-1
To:   Facade-0

From: Flyweight-3
To:   Flyweight-4


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-5783.txt 

commit a95eafdccd398e775646688e9e37e0ae29e1114a
Author: Jonathan Ellis <jbellis@apache.org>

    have loadTokens expunge all tombstones
    patch by jbellis; reviewed by slebresne for CASSANDRA-3579



==================================
 Issue CASSANDRA-3579 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-3579] AssertionError in hintedhandoff - 1.0.5
-----------------

-----------------
Summary: AssertionError in hintedhandoff - 1.0.5
-----------------

-----------------
Issue type: Bug
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Tue, 6 Dec 2011 13:11:23 +0000
-----------------

-----------------
Resolved at: Wed, 11 Jan 2012 19:53:32 +0000
-----------------

-----------------
Assigned to: Sylvain Lebresne
-----------------

-----------------
Description: 

We are running a 8 node cassandra cluster running cassandra 1.0.5.<br/>All our CF use
leveled compaction.  We ran a test where we did a lot<br/>of inserts for 3 days. After
that we started to run tests where some<br/>of the reads could ask for information that
was inserted a while back.<br/>In this scenario we are seeing this assertion error in
HintedHandoff.

ERROR <span class="error">&#91;HintedHandoff:3&#93;</span> 2011-12-05
15:42:04,324<br/>AbstractCassandraDaemon.java (line 133) Fatal exception in
thread<br/>Thread<span
class="error">&#91;HintedHandoff:3,1,main&#93;</span><br/>java.lang.RuntimeException:
java.lang.RuntimeException:<br/>java.util.concurrent.ExecutionException:
java.lang.AssertionError:<br/>originally calculated column size of 470937164 but now it is
470294247<br/>       at
org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)<br/>       at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)<br/>  
    at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)<br/>      
at java.lang.Thread.run(Thread.java:662)<br/>Caused by:
java.lang.RuntimeException:<br/>java.util.concurrent.ExecutionException:
java.lang.AssertionError:<br/>originally calculated column size of 470937164 but now it is
470294247<br/>       at
org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:330)<br/>
      at
org.apache.cassandra.db.HintedHandOffManager.access$100(HintedHandOffManager.java:81)<br/>
      at
org.apache.cassandra.db.HintedHandOffManager$2.runMayThrow(HintedHandOffManager.java:353)<br/>
      at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)<br/>     
 ... 3 more<br/>Caused by:
java.util.concurrent.ExecutionException:<br/>java.lang.AssertionError: originally
calculated column size of<br/>470937164 but now it is 470294247<br/>       at
java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)<br/>       at
java.util.concurrent.FutureTask.get(FutureTask.java:83)<br/>       at
org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:326)<br/>
      ... 6 more<br/>Caused by: java.lang.AssertionError: originally calculated column
size<br/>of 470937164 but now it is 470294247<br/>       at
org.apache.cassandra.db.compaction.LazilyCompactedRow.write(LazilyCompactedRow.java:124)<br/>
      at org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:160)<br/>
      at
org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:158)<br/>   
   at
org.apache.cassandra.db.compaction.CompactionManager$6.call(CompactionManager.java:275)<br/>
      at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)<br/>       at
java.util.concurrent.FutureTask.run(FutureTask.java:138)<br/>       ... 3 more<br/>ERROR
<span class="error">&#91;HintedHandoff:3&#93;</span> 2011-12-05
15:42:04,333<br/>AbstractCassandraDaemon.java (line 133) Fatal exception in
thread<br/>Thread<span
class="error">&#91;HintedHandoff:3,1,main&#93;</span><br/>java.lang.RuntimeException:
java.lang.RuntimeException:<br/>java.util.concurrent.ExecutionException:
java.lang.AssertionError:<br/>originally calculated column size of 470937164 but now it is
470294247<br/>       at
org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)<br/>       at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)<br/>  
    at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)<br/>      
at java.lang.Thread.run(Thread.java:662)<br/>Caused by:
java.lang.RuntimeException:<br/>java.util.concurrent.ExecutionException:
java.lang.AssertionError:<br/>originally calculated column size of 470937164 but now it is
470294247<br/>       at
org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:330)<br/>
      at
org.apache.cassandra.db.HintedHandOffManager.access$100(HintedHandOffManager.java:81)<br/>
      at
org.apache.cassandra.db.HintedHandOffManager$2.runMayThrow(HintedHandOffManager.java:353)<br/>
      at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)<br/>     
 ... 3 more<br/>Caused by:
java.util.concurrent.ExecutionException:<br/>java.lang.AssertionError: originally
calculated column size of<br/>470937164 but now it is 470294247<br/>       at
java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)<br/>       at
java.util.concurrent.FutureTask.get(FutureTask.java:83)<br/>       at
org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:326)<br/>
      ... 6 more<br/>Caused by: java.lang.AssertionError: originally calculated column
size<br/>of 470937164 but now it is 470294247<br/>       at
org.apache.cassandra.db.compaction.LazilyCompactedRow.write(LazilyCompactedRow.java:124)<br/>
      at org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:160)<br/>
      at
org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:158)<br/>   
   at
org.apache.cassandra.db.compaction.CompactionManager$6.call(CompactionManager.java:275)<br/>
      at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)<br/>       at
java.util.concurrent.FutureTask.run(FutureTask.java:138)<br/>       ... 3 more<br/>ERROR
<span class="error">&#91;CompactionExecutor:9931&#93;</span> 2011-12-05
15:42:04,333<br/>AbstractCassandraDaemon.java (line 133) Fatal exception in
thread<br/>Thread<span
class="error">&#91;CompactionExecutor:9931,1,main&#93;</span><br/>java.lang.AssertionError:
originally calculated column size of<br/>470937164 but now it is 470294247<br/>       at
org.apache.cassandra.db.compaction.LazilyCompactedRow.write(LazilyCompactedRow.java:124)<br/>
      at org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:160)<br/>
      at
org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:158)<br/>   
   at
org.apache.cassandra.db.compaction.CompactionManager$6.call(CompactionManager.java:275)<br/>
      at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)<br/>       at
java.util.concurrent.FutureTask.run(FutureTask.java:138)<br/>       at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)<br/>  
    at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)<br/>      
at java.lang.Thread.run(Thread.java:662)
 

-----------------

-----------------
Comments: 

New Comment: 
FWIW, I've seen the same error when bringing a node back up after a brief (5 minute)
down-time.ERROR <span class="error">&#91;HintedHandoff:3&#93;</span> 2011-12-06
16:42:58,822 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread<span
class="error">&#91;HintedHandoff:3,1,main&#93;</span><br/>java.lang.AssertionError<br/>   
    at
org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:301)<br/>
       at
org.apache.cassandra.db.HintedHandOffManager.access$100(HintedHandOffManager.java:81)<br/>
       at
org.apache.cassandra.db.HintedHandOffManager$2.runMayThrow(HintedHandOffManager.java:353)<br/>
       at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)<br/>    
   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)<br/>
       at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)<br/>      
 at java.lang.Thread.run(Thread.java:722) 


New Comment: 
Caleb, your assertion means you had some hint corruption from 1.0.0 (<a
href="https://issues.apache.org/jira/browse/CASSANDRA-3466" title="Hinted handoff not
working after rolling upgrade from 0.8.7 to 1.0.2" class="issue-link"
data-issue-key="CASSANDRA-3466"><del>CASSANDRA-3466</del></a>).  You should remove your
Hint column families from the system/ keyspace. 


New Comment: 
Ramesh, are you using counters?  If so, this may be the same as <a
href="https://issues.apache.org/jira/browse/CASSANDRA-3481" title="During repair,
&quot;incorrect data size&quot; &amp; &quot;Connection reset&quot; errors. Repair unable
to complete." class="issue-link"
data-issue-key="CASSANDRA-3481"><del>CASSANDRA-3481</del></a>. 


New Comment: 
No we are not using counters. 


New Comment: 
I ran into this problem as well. I don't know if it is related, but I started to see
Gossip errors for the node being down and up constantly even when I'm not writing to
Cassandra. Restarting Cassandra fixed the problem.INFO <span
class="error">&#91;CompactionExecutor:648&#93;</span> 2011-12-19 20:41:17,399
CompactionController.java (line 133) Compacting large row
system/HintsColumnFamily:<br/>77777777777777777777777777777770 (73427721 bytes)
incrementally  INFO <span class="error">&#91;FlushWriter:99&#93;</span> 2011-12-19
20:41:17,410 Memtable.java (line 275) Completed flushing
/data/data/system/HintsColumnFamily-hb-141-Data<br/>.db (3022 bytes)<br/>ERROR <span
class="error">&#91;CompactionExecutor:648&#93;</span> 2011-12-19 20:41:19,445
AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread<span
class="error">&#91;Compaction
Executor:648,1,main&#93;</span><br/>java.lang.AssertionError: originally calculated column
size of 66102951 but now it is 66009419<br/>        at
org.apache.cassandra.db.compaction.LazilyCompactedRow.write(LazilyCompactedRow.java:124)<br/>
       at
org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:160)<br/>       
at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:158)<br/>
       at
org.apache.cassandra.db.compaction.CompactionManager$6.call(CompactionManager.java:275)<br/>
       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)<br/>       
at java.util.concurrent.FutureTask.run(FutureTask.java:138)<br/>        at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)<br/>  
     at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)<br/>      
 at java.lang.Thread.run(Thread.java:662)<br/>ERROR <span
class="error">&#91;HintedHandoff:1&#93;</span> 2011-12-19 20:41:19,445
AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread<span
class="error">&#91;HintedHandoff:1,1 ,main&#93;</span><br/>java.lang.RuntimeException:
java.lang.RuntimeException: java.util.concurrent.ExecutionException:
java.lang.AssertionError: originally calc ulated column size of 66102951 but now it is
66009419<br/>        at
org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)<br/>        at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)<br/>  
     at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)<br/>      
 at java.lang.Thread.run(Thread.java:662)<br/>Caused by: java.lang.RuntimeException:
java.util.concurrent.ExecutionException: java.lang.AssertionError: originally calculated
column siz e of 66102951 but now it is 66009419<br/>        at
org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:330)<br/>
       at
org.apache.cassandra.db.HintedHandOffManager.access$100(HintedHandOffManager.java:81)<br/>
   at
org.apache.cassandra.db.HintedHandOffManager.access$100(HintedHandOffManager.java:81)<br/>
       at
org.apache.cassandra.db.HintedHandOffManager$2.runMayThrow(HintedHandOffManager.java:353)<br/>
       at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)<br/>    
   ... 3 more<br/>Caused by: java.util.concurrent.ExecutionException:
java.lang.AssertionError: originally calculated column size of 66102951 but now it
is66009419<br/>        at
java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)<br/>        at
java.util.concurrent.FutureTask.get(FutureTask.java:83)<br/>        at
org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:326)<br/>
       ... 6 more<br/>Caused by: java.lang.AssertionError: originally calculated column
size of 66102951 but now it is 66009419<br/>        at
org.apache.cassandra.db.compaction.LazilyCompactedRow.write(LazilyCompactedRow.java:124)<br/>
       at
org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:160)<br/>       
at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:158)<br/>
       at
org.apache.cassandra.db.compaction.CompactionManager$6.call(CompactionManager.java:275)<br/>
       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)<br/>       
at java.util.concurrent.FutureTask.run(FutureTask.java:138)<br/>        ... 3 more 


New Comment: 
The fact that all these stack traces show that the row size got <b>smaller</b>, and that
HH sets a time to live on its hints starting with <a
href="https://issues.apache.org/jira/browse/CASSANDRA-2034" title="Make Read Repair
unnecessary when Hinted Handoff is enabled" class="issue-link"
data-issue-key="CASSANDRA-2034"><del>CASSANDRA-2034</del></a>, makes me suspect that
somehow columns are expiring in between the first and second LCR passes.  But I don't see
anything obviously wrong with how we are using controller.gcBefore to theoretically
prevent that. 


New Comment: 
I believe I know what is going on. This is bug with CF having gc_grace == 0 (which hints
have). The problem lies in the following line of removeDeleted:<div class="preformatted
panel" style="border-width: 1px;"><div class="preformattedContent panelContent"><pre>if
((c.isMarkedForDelete() &amp;&amp; c.getLocalDeletionTime() &lt;= gcBefore)    ||
c.timestamp() &lt;= cf.getMarkedForDeleteAt()){    iter.remove();}</pre></div></div>and
more precisely the first condition. When that is executed, we have gcbefore &lt;= now but
we <b>can</b> have gcbefore == now if gc_grace == 0 (and since the resolution is the
second, it's not even a very unlikely race).Now for expiring columns it is further
possible that localExpirationTime == gcbefore == now. When that happens,
c.isMarkedForDelete() will return false (thus the column will be kept) because this method
is defined as:<div class="preformatted panel" style="border-width: 1px;"><div
class="preformattedContent panelContent"><pre>public boolean isMarkedForDelete(){   
return (int) (System.currentTimeMillis() / 1000 ) &gt;
localExpirationTime;}</pre></div></div>However, during the second pass, now has changed
and it is possible that we have now &gt; gcbefore. But since gcbefore ==
localExpirationTime, this means that isMarkedForDelete() will be true <b>and</b>
getLocalDeletionTime() &lt;= gcbefore, so the column will be considered tombstone and
gcable.In other word, the current code does not respect the condition that at all time a
column is considered gcable only if it is considered deleted.A rather simple fix consist
in changing the condition in removeDeleted to be<div class="preformatted panel"
style="border-width: 1px;"><div class="preformattedContent panelContent"><pre>if
((c.isMarkedForDelete() &amp;&amp; c.getLocalDeletionTime() &lt; gcBefore)    ||
c.timestamp() &lt;= cf.getMarkedForDeleteAt()){    iter.remove();}</pre></div></div>Note
the strict lesser than operator for the first condition. It fixes it because since we know
that we always have gcbefore &lt;= now, localExpirationTime &lt; gcBefore always imply
that isMarkedForDelete() is true.Attached patch to make that fix (with hopefully useful
comments). 


New Comment: 
I think this change is an improvement, and I also think it's a good thing to make the
semantics of gcBefore match what its name implies, i.e., we collect tombstones from
<b>before</b> that epoch and not before-or-equal-to, but:<ul class="alternate"
type="square">	<li>It's slightly more intuitive for 0 gcgs to mean "this is always gc'd
immediately," not "gc'd after one second."  In practice, I can't see how this could
matter, but it does bother my OCD. <img class="emoticon"
src="https://issues.apache.org/jira/images/icons/emoticons/smile.png" height="16"
width="16" align="absmiddle" alt="" border="0"/></li>	<li>A search for &lt; gcBefore,
&lt;= gcBefore, &gt; gcBefore, &gt;= gcBefore shows some of each.  We're not consistent in
whether we treat it as before or before-or-equal-to, and we need to be.</li>	<li>The
isMarkedForDelete behavior you point out scares me, because that's going to change during
the two LCR passes as well.  I suspect that's going to cause subtle bugs if we don't
create a fixed point in time for which we treat a compaction as happening.  (Maybe just
replace controller.gcBefore with controller.compactionTime and derive gcBefore from that
as a method, instead of a field.)</li></ul> 


New Comment: 
We have the same problem in 0.7 and 0.8 for any CF with 0 gcgs.  For those versions IMO we
should just say "don't do that." 


New Comment: 
<blockquote>It's slightly more intuitive for 0 gcgs to mean "this is always gc'd
immediately,"</blockquote>True, though gc is more a an internal detail in that it doesn't
affect whether a column is returned by queries or not. It only affect whether it will be
removed by a compaction, but that is already so dependent of other timings than it cannot
matter. Or to put it otherwise, that one doesn't bother my own OCD. But it doesn't really
bother me either if gcBefore means before-or-equal so ...<blockquote>A search for &lt;
gcBefore, &lt;= gcBefore, &gt; gcBefore, &gt;= gcBefore shows some of
each.</blockquote>One of the goal of this patch was to actually adds consistency and I
though I had eliminated all '&lt;=' but maybe I missed one. I forgot to search for '&gt;'
and '&gt;=' however. I'll fix.<blockquote>The isMarkedForDelete behavior you point out
scares me, because that's going to change during the two LCR passes as well. I suspect
that's going to cause subtle bugs if we don't create a fixed point in time for which we
treat a compaction as happening. (Maybe just replace controller.gcBefore with
controller.compactionTime and derive gcBefore from that as a method, instead of a
field.)</blockquote>It's an option, and it was even my first idea. But it means that
isMarkedForDelete will take a timestamp, and it's called a lot in the code base. That and
the other related change, I'd be tempted to commit the patch as is for 1.0 and maybe do
the switch to 'compactionTime' for 1.1 onward. 


New Comment: 
<blockquote>I'd be tempted to commit the patch as is for 1.0 and maybe do the switch to
'compactionTime' for 1.1 onward</blockquote>All right, for 1.0 let's just audit for &gt;
&gt;= gcBefore correctness.<blockquote>isMarkedForDelete will take a timestamp, and it's
called a lot in the code base</blockquote>The more I think about it the less I like
"boolean isMarkedForDelete()"...  I like "getExpirationTime()" a lot better.  That allows
combining iMFD and getLDT into a single method (that can return Integer.MAX_VALUE for
Column) that doesn't need any parameters, but doesn't change value during compaction. 


New Comment: 
v2 changes two &gt;= instances to &gt;. 


New Comment: 
+1 on v2, committed on 1.0 branch. How do we merge --record-only with git
again?<blockquote>The more I think about it the less I like "boolean
isMarkedForDelete()"... I like "getExpirationTime()" a lot better.</blockquote>Agreed,
that's much cleaner. I'll do that for 1.1. 


New Comment: 
<blockquote>How do we merge --record-only with git again</blockquote>The closest I found
is <tt>git merge X --strategy=ours</tt>. 


New Comment: 
Created <a href="https://issues.apache.org/jira/browse/CASSANDRA-3716" title="Clean up
isMarkedForDelete / getLocalDeletionTime" class="issue-link"
data-issue-key="CASSANDRA-3716"><del>CASSANDRA-3716</del></a> for the 1.1 followup 


New Comment: 
this is causing the SystemTableTest failure mentioned in <a
href="https://issues.apache.org/jira/browse/CASSANDRA-3727" title="Fix unit tests failure"
class="issue-link" data-issue-key="CASSANDRA-3727"><del>CASSANDRA-3727</del></a> 


New Comment: 
Switching from &lt;= to &lt; means that getColumnFamily will now include tombstones for
just-deleted column with gcgs == 0.For clients this is harmless (since we drop tombstones
in the coordinator after RR), but internal code needs to be more careful.  patch attached
to have loadTokens expunge all tombstones. 


New Comment: 
+1 


