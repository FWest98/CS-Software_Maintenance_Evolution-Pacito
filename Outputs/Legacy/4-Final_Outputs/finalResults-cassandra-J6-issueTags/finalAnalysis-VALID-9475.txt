Pattern changes caused by commit: 079ae68fb7086259439491e6a10bc2d8a947f52c

From: Strategy-1
To:   Strategy-0


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-9475.txt 

commit 079ae68fb7086259439491e6a10bc2d8a947f52c
Author: Jonathan Ellis <jbellis@apache.org>

    Reduce SSTableLoader memory usage
    patch by jbellis; reviewed by dbrosius for CASSANDRA-5555



==================================
 Issue CASSANDRA-5555 Description 
=======================================

Project: Cassandra
-----------------

-----------------
Title: [CASSANDRA-5555] Allow sstableloader to handle a larger number of files
-----------------

-----------------
Summary: Allow sstableloader to handle a larger number of files
-----------------

-----------------
Issue type: Improvement
-----------------

-----------------
Current status: Resolved
-----------------

-----------------
Created at: Fri, 10 May 2013 16:07:59 +0000
-----------------

-----------------
Resolved at: Thu, 18 Jul 2013 20:15:02 +0000
-----------------

-----------------
Assigned to: Tom Hobbs
-----------------

-----------------
Description: 

With the default heap size, sstableloader will OOM when there are roughly 25k files in
the directory to load.  It's easy to reach this number of files in a single LCS column
family.

By avoiding creating all SSTableReaders up front in SSTableLoader, we should be
able to increase the number of files that sstableloader can handle considerably.
 

-----------------

-----------------
Comments: 

New Comment: 
How much of a rewrite would this be, <a
href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dbrosius"
class="user-hover" rel="dbrosius">David Brosius</a>? 


New Comment: 
A premature patch added to see if approach is relatively ok, haven't formulated tests yet,
so <b>definitely</b> not ready yet.Also note that this implementation leaks into
StorageService, which is probably not desired, and a real fix probably wants a separate
interface into SSTableLoader.stream() as opposed to a complete replace. But not
sure.(patch against trunk) 


New Comment: 
You're right, it's a bit messy. <img class="emoticon"
src="https://issues.apache.org/jira/images/icons/emoticons/smile.png" height="16"
width="16" align="absmiddle" alt="" border="0"/>Digging in a bit, I'm actually a bit
confused by the premise here &#8211; unless you're generating sstables to load on a
machine with vastly more disk space than your cluster members, you should be able to open
the sstables you're generating, since that's what the nodes you're streaming to will have
to do.(Before looking at the code, I assumed we were opening some kind of scanner or
buffer per sstable a la <a href="https://issues.apache.org/jira/browse/CASSANDRA-4142"
title="OOM Exception during repair session with LeveledCompactionStrategy"
class="issue-link" data-issue-key="CASSANDRA-4142"><del>CASSANDRA-4142</del></a> but it
looks like it's just the SSTableReader.)<blockquote>With the default heap size,
sstableloader will OOM when there are roughly 25k files in the directory to
load</blockquote>This default?<div class="code panel" style="border-width: 1px;"><div
class="codeContent panelContent"><pre class="code-java">$JAVA -ea -cp $CLASSPATH
-Xmx256M</pre></div></div>Honestly I think telling people "increase the heap size" is a
perfectly adequate solution if that's really what we're running with right now. 
Increasing it to 1GB out of the box also seems reasonable. 


New Comment: 
At the very least we should make the heap size configurable with an environment variable
instead of hard coded in the executable. But I would still prefer a solution that doesn't
require using as much memory to begin with. That makes it easier to restore multiple
column families at the same time (potentially hundreds of thousands of sstables), and
makes it easier to run the sstableloader on a node that is already running cassandra
(restoring a local backup instead of a remote one). 


New Comment: 
Remember that memory use is primarily proportional to data size, not sstable count.In any
case, ISTM that it should be fairly easy to wrap sstableloader in a script that gives it X
GB of files at a time. 


New Comment: 
<blockquote>In any case, ISTM that it should be fairly easy to wrap sstableloader in a
script that gives it X GB of files at a time.</blockquote>Possible, but not trivial, since
sstableloader works on a directory. 


New Comment: 
Well, that should be relatively easy to change. 


New Comment: 
I have a better idea.  Should be relatively easy to special case SSTableReader.open to
just not load BF + partition summary in "batch mode." 


New Comment: 
+1 


New Comment: 
Patchset posted to <a href="https://github.com/jbellis/cassandra/commits/5555"
class="external-link" rel="nofollow">https://github.com/jbellis/cassandra/commits/5555</a> 


New Comment: 
'RandomAccessReader in' should be closed in finally block. 


New Comment: 
pushed fix 


New Comment: 
I am cut off from the network at present.....that's all I see on visual inspection.
hopefully I'll be up tomorrow and can try it out. (Phone access <img class="emoticon"
src="https://issues.apache.org/jira/images/icons/emoticons/smile.png" height="16"
width="16" align="absmiddle" alt="" border="0"/> 


New Comment: 
saved here as a patch for posterity+1 lgtm 


New Comment: 
committed 


New Comment: 
<a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbellis"
class="user-hover" rel="jbellis">Jonathan Ellis</a> did you still want to increase the
default heap size?  Just want to make sure you didn't forget to increase it if you
intended to.FYI, we'll likely do a stress test to see what the new limit is with these
changes. 


New Comment: 
Increasing the heap size shouldn't be necessary, since virtually nothing's on the heap
now. 


New Comment: 
Repro steps 


New Comment: 
Added repro steps based on Cassandra 1.1.9 


New Comment: 
We already committed a fix for 1.2.6. 


New Comment: 
Updated repro steps. Reviewed by Mike Bulman 


New Comment: 
<blockquote>We already committed a fix for 1.2.6.</blockquote>Yeah.  Alex is just helping
to QA this, so those are the steps to reproduce pre-1.2.6, and then we'll run them again
on 1.2.6+ 


New Comment: 
This fix can send wrong "estimated number of keys" for creating BF on the streamed node,
since calculating estimate uses index summary.My proposed fix is to make index summary
completely optional. That is, when Summary.db file is present, load that and use it. We
also add an option not to load Summary.db. And when the file is not present nor the user
choose not to load the summary, we just scan sequentially on index file(Index.db) for
"estimated number of keys". 


New Comment: 
<blockquote>This fix can send wrong "estimated number of keys" for creating BF on the
streamed node, since calculating estimate uses index summary.</blockquote>Why is that a
problem? 


New Comment: 
When you load SSTable via SSTableLoader, it creates index summary of 1 entry with 1 index
interval. So the loader will send estimated number of keys of 1 (or 0) every time
regardless of actual keys in range, it may create BF of small size that produces higher
false positive unintentionally. 


New Comment: 
Ah, right.  Related to <a href="https://issues.apache.org/jira/browse/CASSANDRA-5542"
title="BulkLoader is broken in trunk" class="issue-link"
data-issue-key="CASSANDRA-5542"><del>CASSANDRA-5542</del></a>.I think we can simplify a
bit though.  Leave out the option, and have sstableloader load if present, but just
discard it after load instead of keeping it memory resident.May also be simpler to go
through the "generate summary if it doesn't exist" path than add separate "count keys if
we don't have a summary" code.  Personally I'd prefer to just make summary required, but
we probably can't do that this late in 1.2.Is this messy enough that we should just revert
and do this in trunk?  On the bright side we could make summary required. <img
class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.png"
height="16" width="16" align="absmiddle" alt="" border="0"/> 


New Comment: 
well, all we've done now is get to run the code that eliminates IndexSummary<br/>it's
going to take a new patch to eliminate that BufferedSegmentedFile<br/>(c) Jonathan Ellis 


New Comment: 
To clarify: Alex was still reproducing OOM, but his initial heap dump showed that
IndexSummary was the primary culprit.  Once we started running the code from current 1.2,
it still OOMs but the culprit is now BufferedSegmentedFile.  (Looks like our reader
pooling is biting us in the butt.) 


New Comment: 
Updated "repro steps instruction" with setting ulimits for opened files on macOs" and
dumping memory on OOM exception 


New Comment: 
patch to avoid pooling readers during bulk load 


New Comment: 
We need to fix the issue Yuki raised before we can ship this.  This is going to take a bit
of work, so in the meantime I've reverted the original commit from 1.2 and will move this
ticket to 1.2.7.In the meantime, I've created <a
href="https://github.com/jbellis/cassandra/commits/5555-2" class="external-link"
rel="nofollow">https://github.com/jbellis/cassandra/commits/5555-2</a> with the memory
reduction work (both IndexSummary and SegmentedFile) so Alex can continue to test that
aspect. 


New Comment: 
To clarify, will this also fix the OOM when the total number of files is relatively small
(~30 sstables) but the total data size is large (~80GB+)? 


New Comment: 
Yes. 


New Comment: 
Attached patch <tt>5555-fix-heap-and-streaming-1.2.patch</tt> (and <a
href="https://github.com/thobbs/cassandra/tree/5555" class="external-link"
rel="nofollow">branch</a>) is based on Jonathan's 5555-2 branch, but fixes the estimated
keys issue that Yuki brought up.The index summary was being used just before streaming to
calculate both the estimated number of keys and the range of positions within the sstable
files to stream.  Those are now calculated upfront and then the index summary reference is
dropped so that it can be GC'ed.I did some minor stress testing, but nothing as complete
as Alex's steps.  (Let me know if I should do those instead of Alex.) 


New Comment: 
The logic looks good to me.  Style nits:<ul class="alternate" type="square">	<li>Prefer
more concise field names like <tt>streamingDetails</tt> to
<tt>endpointToStreamingDetails</tt>.  With the type information available, we can see that
it's a <tt>Map&lt;InetAddress, EndpointStreamingDetails&gt;</tt> and don't need to
redundantly "encode" that in the field name.</li>	<li>By convention, Java foreach loops
have a space before as well as after the colon</li>	<li>in the <tt>stream</tt> method, you
replaced a <tt>for</tt> block of the form</li></ul><div class="code panel"
style="border-width: 1px;"><div class="codeContent panelContent"><pre
class="code-java"><span class="code-keyword">for</span> ...  <span
class="code-keyword">if</span>    exceptional <span class="code-keyword">case</span>   
<span class="code-keyword">continue</span>  main <span
class="code-keyword">case</span></pre></div></div>with<div class="code panel"
style="border-width: 1px;"><div class="codeContent panelContent"><pre
class="code-java"><span class="code-keyword">for</span> ...  <span
class="code-keyword">if</span>    exceptional <span class="code-keyword">case</span> 
<span class="code-keyword">else</span>    main <span
class="code-keyword">case</span></pre></div></div>Generally it's good policy to keep the
"main case" less nested, which the if-continue form lets us do.  This keeps your mental
stack less cluttered when you're reasoning about it.<ul class="alternate"
type="square">	<li>The <tt>List&lt;List&lt;Pair&lt;Long, Long&gt;&gt;&gt;</tt> is probably
a bit more hackish than we want here.  How about adding an sstable reference into the
details class so you can associate them that way, instead of "sstable 0 goes with list
entry 0?"  Something like this.  ((<tt>streamingDetails</tt> would then become a
Multimap.)</li></ul><div class="code panel" style="border-width: 1px;"><div
class="codeContent panelContent"><pre class="code-java">    <span
class="code-keyword">private</span> <span class="code-keyword">class
</span>SSTableStreamingSections    {        <span class="code-keyword">public</span> <span
class="code-keyword">final</span> SSTableReader sstable;        <span
class="code-keyword">public</span> <span class="code-keyword">final</span> List&lt;<span
class="code-object">Long</span>, <span class="code-object">Long</span>&gt; sections;      
         <span class="code-keyword">public</span> <span class="code-keyword">final</span>
<span class="code-object">int</span> estimatedKeys;        <span
class="code-keyword">private</span> SSTableStreamingSections(SSTableReader sstable,
List&lt;<span class="code-object">Long</span>, <span class="code-object">Long</span>&gt;
sections, <span class="code-object">int</span> estimatedKeys)        {            <span
class="code-keyword">this</span>.sstable = sstable;            <span
class="code-keyword">this</span>.sections = sections;            <span
class="code-keyword">this</span>.estimatedKeys = estimatedKeys;        }   
}</pre></div></div> 


New Comment: 
Thanks for the style tips, much appreciated.
<tt>5555-fix-heap-and-streaming-1.2-v2.patch</tt> makes the suggested changes (on the same
<a href="https://github.com/thobbs/cassandra/tree/5555" class="external-link"
rel="nofollow">branch</a>). 


New Comment: 
Looks good.  Can you add a patch against trunk? 


New Comment: 
<span class="error">&#91;bump&#93;</span> 


New Comment: 
Just waiting on a commit on <a href="https://issues.apache.org/jira/browse/CASSANDRA-5542"
title="BulkLoader is broken in trunk" class="issue-link"
data-issue-key="CASSANDRA-5542"><del>CASSANDRA-5542</del></a> before I put in the last
piece of the trunk patch. 


New Comment: 
Is it going to trunk or cassandra-1.2? 


New Comment: 
Yes. 


New Comment: 
Attached file <tt>5555-fix-heap-and-streaming-trunk.patch</tt> (and <a
href="https://github.com/thobbs/cassandra/tree/CASSANDRA-5555-trunk" class="external-link"
rel="nofollow">branch</a>) should apply to the latest trunk. 


New Comment: 
committed 


