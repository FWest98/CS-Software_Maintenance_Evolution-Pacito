Pattern changes caused by commit: dc96e2286cee2501b4e8a8820a030f500bfeaa2f

From: Mediator-0
To:   Mediator-1


=========================
       NEW GIT LOG
=========================

This commit refers to file: VALID-61.txt 

commit dc96e2286cee2501b4e8a8820a030f500bfeaa2f
Author: Konstantin Shvachko <shv@apache.org>

    HDFS-462. loadFSImage should close edits file. Contributed by Jakob Homan.



==================================
 Issue HDFS-462 Description 
=======================================

Project: Hadoop HDFS
-----------------

-----------------
Title: [HDFS-462] Unit tests not working under Windows
-----------------

-----------------
Summary: Unit tests not working under Windows
-----------------

-----------------
Issue type: Bug
-----------------

-----------------
Current status: Closed
-----------------

-----------------
Created at: Mon, 6 Jul 2009 17:51:08 +0000
-----------------

-----------------
Resolved at: Mon, 13 Jul 2009 23:46:23 +0000
-----------------

-----------------
Assigned to: Jakob Homan
-----------------

-----------------
Description: 

Unit tests are failing on windows due to a problem with rename. <br/>The failing code is
around line 520 in FSImage.java: 
<div class="preformatted panel" style="border-width:
1px;"><div class="preformattedContent panelContent"><pre>      assert curDir.exists() :
"Current directory must exist.";      assert !prevDir.exists() : "prvious directory must
not exist.";      assert !tmpDir.exists() : "prvious.tmp directory must not exist.";     
// rename current to tmp      rename(curDir, tmpDir);      // save new image      if
(!curDir.mkdir())        throw new IOException("Cannot create directory " +
curDir);</pre></div></div>
and seems related to some open file or directory
 

-----------------

-----------------
Comments: 

New Comment: 
Yes, as we traced with Luca, the rename of <tt>current</tt> to <tt>previous.tmp</tt> fails
because <tt>current/edits</tt> remains open after <tt>loadFSImaeg()</tt>. WinNT does not
let rename directories if there are open files in it. This was introduced by <a
href="https://issues.apache.org/jira/browse/HADOOP-5314" title="needToSave incorrectly
calculated in loadFSImage()" class="issue-link"
data-issue-key="HADOOP-5314"><del>HADOOP-5314</del></a>. For regular name-node start up
this makes sense, but fails in other scenarios.We should really-really resurrect windows
build at least once a week as we used to have. 


New Comment: 
MiniDFSCluster also does not work in Windows.<div class="code panel" style="border-width:
1px;"><div class="codeContent panelContent"><pre class="code-java"><span
class="code-comment">//The following test failed in Windows.  </span><span
class="code-comment">//See also the attached log
TEST-org.apache.hadoop.hdfs.TestHdfs.txt</span><span class="code-keyword">public</span>
<span class="code-keyword">class </span>TestHdfs <span class="code-keyword">extends</span>
junit.framework.TestCase {  <span class="code-keyword">public</span> void testHdfs() <span
class="code-keyword">throws</span> IOException {    <span class="code-keyword">new</span>
MiniDFSCluster(<span class="code-keyword">new</span> Configuration(), 1, <span
class="code-keyword">true</span>, <span class="code-keyword">null</span>); 
}}</pre></div></div><div class="preformatted panel" style="border-width: 1px;"><div
class="preformattedContent panelContent"><pre>Testcase: testHdfs took 1.219 sec	Caused an
ERRORAll specified directories are not accessible or do not exist.java.io.IOException: All
specified directories are not accessible or do not exist.	at
org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:370)	at
org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:99)	at
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:255)	at
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.&lt;init&gt;(FSNamesystem.java:236)	at
org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:254)	at
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:299)	at
org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:405)	at
org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:399)	at
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1159)	at
org.apache.hadoop.hdfs.MiniDFSCluster.&lt;init&gt;(MiniDFSCluster.java:276)	at
org.apache.hadoop.hdfs.MiniDFSCluster.&lt;init&gt;(MiniDFSCluster.java:120)	at
org.apache.hadoop.hdfs.TestHdfs.testHdfs(TestHdfs.java:25)</pre></div></div> 


New Comment: 
Attaching patch that fixes problem.  Konstantin tested on his Windows box and it worked. 
Passes unit tests.  Nicholas, I don't believe your issue is due to this problem, but
rather from the URI patch that's related to this one. 


New Comment: 
submitting patch 


New Comment: 
Nicholas your case falls under <a href="https://issues.apache.org/jira/browse/HDFS-456"
title="Problems with dfs.name.edits.dirs as URI" class="issue-link"
data-issue-key="HDFS-456"><del>HDFS-456</del></a>. See error messages before that
complaining the path is not a uri.Checked the patch on windows. TestDistributedUpgrade
passes with, fails without it.<br/>+1 


New Comment: 
-1 overall.  Here are the results of testing the latest attachment <br/>  <a
href="http://issues.apache.org/jira/secure/attachment/12413051/HDFS-462.patch"
class="external-link"
rel="nofollow">http://issues.apache.org/jira/secure/attachment/12413051/HDFS-462.patch</a><br/>
 against trunk revision 792881.    +1 @author.  The patch does not contain any @author
tags.    -1 tests included.  The patch doesn't appear to include any new or modified
tests.<br/>                        Please justify why no new tests are needed for this
patch.<br/>                        Also please list what manual steps were performed to
verify this patch.    +1 javadoc.  The javadoc tool did not generate any warning messages.
   +1 javac.  The applied patch does not increase the total number of javac compiler
warnings.    +1 findbugs.  The patch does not introduce any new Findbugs warnings.    +1
release audit.  The applied patch does not increase the total number of release audit
warnings.    -1 core tests.  The patch failed core unit tests.    -1 contrib tests.  The
patch failed contrib unit tests.Test results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-vesta.apache.org/15/testReport/"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-vesta.apache.org/15/testReport/</a><br/>Findbugs
warnings: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-vesta.apache.org/15/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-vesta.apache.org/15/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html</a><br/>Checkstyle
results: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-vesta.apache.org/15/artifact/trunk/build/test/checkstyle-errors.html"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-vesta.apache.org/15/artifact/trunk/build/test/checkstyle-errors.html</a><br/>Console
output: <a
href="http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-vesta.apache.org/15/console"
class="external-link"
rel="nofollow">http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-vesta.apache.org/15/console</a>This
message is automatically generated. 


New Comment: 
Again, no new tests as is fixing a defect that's being caught by the current unit tests
(under Windows at least).  Patch is ready to go. 


New Comment: 
I just committed this. Thank you Jakob. 


